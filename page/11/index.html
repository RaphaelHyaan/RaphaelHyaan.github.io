<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Raphael's Home - 自由自在</title><meta name="author" content="Raphael Hyaan"><meta name="copyright" content="Raphael Hyaan"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="何日可谓归去来">
<meta property="og:type" content="website">
<meta property="og:title" content="Raphael&#39;s Home">
<meta property="og:url" content="http://raphaelhyaan.cn/page/11/index.html">
<meta property="og:site_name" content="Raphael&#39;s Home">
<meta property="og:description" content="何日可谓归去来">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Fe747243b42e6168d02fdf8bccbbd4ea.jpg">
<meta property="article:author" content="Raphael Hyaan">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Fe747243b42e6168d02fdf8bccbbd4ea.jpg"><link rel="shortcut icon" href="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Flana cat 002.png"><link rel="canonical" href="http://raphaelhyaan.cn/page/11/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Raphael\'s Home',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2025-01-09 22:22:14'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/butterflyChange/css/code.css"><meta name="generator" content="Hexo 7.0.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Fe747243b42e6168d02fdf8bccbbd4ea.jpg" onerror="onerror=null;src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffriend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">150</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">49</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">18</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/Reading/"><i class="fa-fw fas fa-book"></i><span> Reading</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> Gallery</span></a></li><li><a class="site-page child" href="/Video/"><i class="fa-fw fas fa-video"></i><span> Video</span></a></li></ul></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Flana cat 002.png')"><nav id="nav"><span id="blog-info"><a href="/" title="Raphael's Home"><span class="site-name">Raphael's Home</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/Reading/"><i class="fa-fw fas fa-book"></i><span> Reading</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> Gallery</span></a></li><li><a class="site-page child" href="/Video/"><i class="fa-fw fas fa-video"></i><span> Video</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">Raphael's Home</h1><div id="site-subtitle"><span id="subtitle"></span></div><div id="site_social_icons"><a class="social-icon" href="https://github.com/raphaelhyaan" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:raphael.ma.yuhan@outlook.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left"><a href="/2024/01/20/informatique/deeplearning/Generative_10/" title="Chapter 10 Advanced GANs 各种各样的GAN"><img class="post-bg" src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fgenerative.jpg" onerror="this.onerror=null;this.src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="Chapter 10 Advanced GANs 各种各样的GAN"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/01/20/informatique/deeplearning/Generative_10/" title="Chapter 10 Advanced GANs 各种各样的GAN">Chapter 10 Advanced GANs 各种各样的GAN</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-01-20T16:19:06.000Z" title="发表于 2024-01-20 17:19:06">2024-01-20</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%94%9F%E6%88%90%E5%BC%8F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">学习笔记-生成式神经网络</a></span></div><div class="content">Chapter 10 Advanced GANs
各种各样的GAN

在本次学习的最后，回归最初学习的目的，来尝试了解各种各样的GAN网络。我可能会尝试实现其中的一些模型。



三个的建立在早期论文思想上的重要模型ProGAN → StyleGAN → StyleGAN2

了解ProGAN模型。
理解ProGAN如何被改造以构建StyleGAN
探索StyleGAN如何被调整以创建StyleGAN2
了解这些模型的关键贡献，包括渐进式训练、自适应实例归一化、权重调制和解调以及路径长度正则化。’

两个引入了注意力机制的模型SAGAN → BigGAN

了解Self-Attention GAN (SAGAN)的架构，该架构将注意力机制纳入GAN框架。
了解BigGAN如何扩展SAGAN论文中的想法以产生高质量的图像。

两个融合了VAE，Transformers和GAN思想的模型VQ-GAN → ViT VQ-GAN

了解VQ-GAN如何使用码本将图像编码为可以使用Transformer建模的离散序列的token。
了解ViT VQ-G ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2024/01/20/informatique/deeplearning/Generative_9/" title="Chapter 9 Transformers"><img class="post-bg" src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fgenerative.jpg" onerror="this.onerror=null;this.src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="Chapter 9 Transformers"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/01/20/informatique/deeplearning/Generative_9/" title="Chapter 9 Transformers">Chapter 9 Transformers</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-01-20T15:19:15.000Z" title="发表于 2024-01-20 16:19:15">2024-01-20</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%94%9F%E6%88%90%E5%BC%8F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">学习笔记-生成式神经网络</a></span></div><div class="content">Chapter 9 Transformers

由于文本生成不是我的主要学习目的，本章学习不会尝试使用PyTorch复现。另一个原因是Diffusion的PyTorch版主直到本章开始学习都不能正常工作。考虑到目前对一些知识还处于一知半解的状态，且我的学习目的也并非实现Diffusion或者GPT这些网络，故暂时不会进行使用PyTorch的重现。


尽管如此，我还是在原文提供的GPT上进行一些“随心所欲”，或者说“完全不知道原理只是瞎改”的，修改。尽管我现在还有得到结果，但可以预料到势必会导致表现变差。


PyTorch的重现已经添加，基本架构相同，只是作用在另一个任务上。


介绍

Transformer神经网络是一种不需要循环或者卷积架构，依赖于注意力机制的神经网络。是目前用于文本生成的最重要的架构。
GPT 全程Generative Pre-Training
是一种能够在大量文本数据上训练的Transformer架构。在预训练期间，模型被训练为在给定先前单词的情况下预测序列中的下一个单词。此过程称为语言建模，用于教导模型理解自然语言的结构和模式 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2024/01/20/informatique/deeplearning/Generative_8/" title="Chapter 8 Diffusion Models 扩散模型"><img class="post-bg" src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fgenerative.jpg" onerror="this.onerror=null;this.src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="Chapter 8 Diffusion Models 扩散模型"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/01/20/informatique/deeplearning/Generative_8/" title="Chapter 8 Diffusion Models 扩散模型">Chapter 8 Diffusion Models 扩散模型</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-01-20T15:19:14.000Z" title="发表于 2024-01-20 16:19:14">2024-01-20</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%94%9F%E6%88%90%E5%BC%8F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">学习笔记-生成式神经网络</a></span></div><div class="content">Chapter 8 Diffusion Models
扩散模型


这个模型很有意思，我会尝试使用PyTorch实现。

介绍

扩散模型是过去十年中引入的最具影响力和影响力的图像生成生成建模技术之一。扩散这个名字的灵感来自于热力学扩散特性

突破性的扩散模型论文于 2020
年夏天发表。该论文揭示了扩散模型和基于分数的生成模型之间的深层联系，作者训练了一个扩散模型，可以在多个数据集胜过竞争对手
GAN，称为去噪扩散概率模型 (DDPM)
扩散电视

我们再次从一个小故事开始。


💡
您站在一家出售电视机的电子商店里。这里有数百台相同的电视机按顺序连接在一起，一直延伸到商店的后面。更奇怪的是，最前面的几台电视机似乎只显示随机的静态噪声。
店主解释说，这是新的DiffuseTV型号。在制造过程中，DiffuseTV接触了数千张以前的电视节目的图像，但是这些图像都被逐渐加入了随机的静态噪声，直到它们与纯随机噪声无法区分。然后，电视机被设计成以小步骤消除随机噪声，尝试预测在加入噪声之前图像是什么样子的。
可以看到，当走进商店时，每台电视机上的图像 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2024/01/20/informatique/deeplearning/Generative_7/" title="Chapter 7 Energy-Based Models 基于能量的模型"><img class="post-bg" src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fgenerative.jpg" onerror="this.onerror=null;this.src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="Chapter 7 Energy-Based Models 基于能量的模型"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/01/20/informatique/deeplearning/Generative_7/" title="Chapter 7 Energy-Based Models 基于能量的模型">Chapter 7 Energy-Based Models 基于能量的模型</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-01-20T15:19:13.000Z" title="发表于 2024-01-20 16:19:13">2024-01-20</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%94%9F%E6%88%90%E5%BC%8F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">学习笔记-生成式神经网络</a></span></div><div class="content">Chapter 7
Energy-Based Models 基于能量的模型

当前笔记基本没有涉及对代码的讨论。但这个模型跟我的需求在原理上很契合，在进一步尝试时可能会补充这份笔记。


介绍

基于能量的模型是一类广泛的生成式模型。它借鉴了物理系统建模的关键思想，即事件的概率可以使用玻尔兹曼分布来表示。玻尔兹曼分布是一种将实值能量函数归一化到
\([0,1]\)的特定函数。

Long-au-Vin 的长跑队

我们依然从一个小故事开始说起。


💡 黛安·米克斯是 Long-au-Vin
的长跑队主教练，以其卓越的训练能力而闻名。她的方法是基于评估每个运动员的能量水平，她能准确地感知运动员比赛后剩余的能量。她定期训练自己，通过测量已知精英运动员和俱乐部最佳运动员的能量感知能力之间的对比。
她的真正的魔力在于她能将平庸的跑者转变为顶级跑者。她测量运动员当前的能量水平，找出运动员需要做出的最佳调整以提高他们下次的表现。这个过程会一直持续，直到最终运动员无法与世界级跑者区分。

基于能量的模型
基于能量的模型使用玻尔兹曼分布来对真实分布建模： ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2024/01/20/informatique/deeplearning/Generative_6/" title="Chapter 6 Normalizing Flow Models 标准化流模型"><img class="post-bg" src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fgenerative.jpg" onerror="this.onerror=null;this.src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="Chapter 6 Normalizing Flow Models 标准化流模型"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/01/20/informatique/deeplearning/Generative_6/" title="Chapter 6 Normalizing Flow Models 标准化流模型">Chapter 6 Normalizing Flow Models 标准化流模型</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-01-20T15:19:11.000Z" title="发表于 2024-01-20 16:19:11">2024-01-20</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%94%9F%E6%88%90%E5%BC%8F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">学习笔记-生成式神经网络</a></span></div><div class="content">Chapter 6
Normalizing Flow Models 标准化流模型

标准化流模型是一种生成模型，用于将一个原始分布通过学习的变换映射到另一个已知的概率分布。它可以把简单的概率密度（比如高斯分布）形式转化成某种复杂的分布形式。所以或许能把标准化流模型称为正态流模型。


本章笔记不包括使用PyTorch的重现，但是本章代码并不困难，未来有兴趣或者会使用这部分知识时会进行复现。


背景故事

我们依然从一个小故事开始讲起，这次故事的主角是雅各布和F.L.O.W.机器


💡
雅各布是一个数字绘画提供商，但有所不同。你递给店主一套你最喜欢的画，他把它们穿过机器。F.L.O.W.机器开始嗡嗡作响，过了一会儿，输出一组随机生成的数字。店主递给你数字表，然后开始走到收银台，计算你在数字化过程和F.L.O.W.盒子中欠他的钱。你会问店主，你应该如何处理这一长串数字，以及如何取回你最喜欢的画作。
店主翻了个白眼，好像答案应该是显而易见的。他走回机器前，把长长的数字表传了过去，这次是从对面传来的。你再次听到机器的嗡嗡声，困惑地等待着，直到你原来的画作从 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2024/01/20/informatique/deeplearning/Generative_5/" title="Chapter 5 Autoregressive Models 自回归模型"><img class="post-bg" src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fgenerative.jpg" onerror="this.onerror=null;this.src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="Chapter 5 Autoregressive Models 自回归模型"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/01/20/informatique/deeplearning/Generative_5/" title="Chapter 5 Autoregressive Models 自回归模型">Chapter 5 Autoregressive Models 自回归模型</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-01-20T15:19:10.000Z" title="发表于 2024-01-20 16:19:10">2024-01-20</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%94%9F%E6%88%90%E5%BC%8F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">学习笔记-生成式神经网络</a></span></div><div class="content">Chapter 5
Autoregressive Models 自回归模型

在本章中，我们将探讨两种自回归模型，LSTM
~~Literary Society for Troublesome Miscreants~~ long short-term
memory networks 和
PixelCNN，而另一种非常成功的自回归模型transformer会在之后的内容中提到。


Long Short-Term
Memory Network (LSTM)
介绍
流氓文学会

💡
接下来我们参考简单的故事。考虑一位监狱的总管先生，他利用手中的囚犯，发明了一种独特的小说撰写方式，被他称为流氓文学会********Literary
Society for Troublesome
Miscreants，简称LSTM。********在他的设计下，囚犯将湮灭人性，而成为LSTM的一个节点。
每天，这位总管先生将小说的最后一个单词抛给LSTM，LSTM中的囚犯根据这个单词，其他囚犯的观点和自己旧有的观点，给出自己新的观点；并根据新词和其他囚犯的观点决定将多少观 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2024/01/20/informatique/deeplearning/Generative_4/" title="Chapter 4 Generative Adversarial Networks 生成对抗网络"><img class="post-bg" src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fgenerative.jpg" onerror="this.onerror=null;this.src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="Chapter 4 Generative Adversarial Networks 生成对抗网络"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/01/20/informatique/deeplearning/Generative_4/" title="Chapter 4 Generative Adversarial Networks 生成对抗网络">Chapter 4 Generative Adversarial Networks 生成对抗网络</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-01-20T15:19:09.000Z" title="发表于 2024-01-20 16:19:09">2024-01-20</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%94%9F%E6%88%90%E5%BC%8F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">学习笔记-生成式神经网络</a></span></div><div class="content">Chapter
4 Generative Adversarial Networks 生成对抗网络

GAN的介绍

GAN包含两个部分生成器Generator和判别器Discriminator。生成器基于随机噪音生成图像，判别器判断生成器生成的图像是否为真实存在的图像。生成器的训练目的是尽可能生成判别器识别不出来的图像，而判别器的训练目的是尽可能区分生成器生成的图像和真实存在的图像。
Deep Convolutional GAN(DCGAN)

在这一部分，我们会跟随作者的步伐使用Keras构建一个DCGAN网络。同时我也会尝试使用PyTorch重现这些代码。

数据集

我们使用Images of LEGO Bricks dataset数据集。


数据集加载
Tensorflow的数据集加载方法包括使用image_dataset_from_directory的数据加载和使用preprocess函数的预处理
1234567891011121314train_data = utils.image_dataset_from_directory(    & ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2024/01/20/informatique/deeplearning/Generative_3/" title="Chapter 3 Variational Autoencoders 自动变分编码器"><img class="post-bg" src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fgenerative.jpg" onerror="this.onerror=null;this.src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="Chapter 3 Variational Autoencoders 自动变分编码器"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/01/20/informatique/deeplearning/Generative_3/" title="Chapter 3 Variational Autoencoders 自动变分编码器">Chapter 3 Variational Autoencoders 自动变分编码器</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-01-20T15:19:08.000Z" title="发表于 2024-01-20 16:19:08">2024-01-20</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%94%9F%E6%88%90%E5%BC%8F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">学习笔记-生成式神经网络</a></span></div><div class="content">Chapter 3
Variational Autoencoders 自动变分编码器

介绍

2013 年，Diederik P. Kingma 和 Max Welling
发表了一篇论文，为一种称为变分自编码器 (VAE) 的神经网络奠定了基础。

故事

💡
想象一下，你面前的地板上堆满了你所有的衣服——裤子、上衣、鞋子和外套，款式各异。你的造型师布莱恩越来越沮丧，因为他花了很长时间才能找到你需要的物品，因此他制定了一个聪明的计划。他告诉你把你的衣服整理成一个无限高和无限宽的衣柜。当您想要索取特定物品时，您只需告诉布莱恩它的位置，他就会使用他值得信赖的缝纫机从头开始缝制该物品。很快就会发现，您需要将相似的项目彼此靠近放置，以便
Brian 可以仅根据其位置准确地重新创建每个项目。
经过几周的练习，你和布莱恩已经适应了彼此对衣柜布局的理解。现在您可以告诉布莱恩您想要的任何衣服的位置，他可以从头开始准确地缝制它！这给了你一个想法——如果你给布莱恩一个空的衣柜位置，会发生什么？令你惊讶的是，你发现布莱恩能够完全生成以前不存在的新衣服！这个过程并不完美，但你现 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2024/01/20/informatique/deeplearning/Generative_2/" title="Chapter 2 Deep Learning"><img class="post-bg" src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fgenerative.jpg" onerror="this.onerror=null;this.src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="Chapter 2 Deep Learning"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/01/20/informatique/deeplearning/Generative_2/" title="Chapter 2 Deep Learning">Chapter 2 Deep Learning</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-01-20T15:19:07.000Z" title="发表于 2024-01-20 16:19:07">2024-01-20</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%94%9F%E6%88%90%E5%BC%8F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">学习笔记-生成式神经网络</a></span></div><div class="content">Chapter 2 Deep Learning
神经网络

神经网络由一系列堆叠层组成。每层都包含通过一组权重连接到前一层单元的单元。正如我们将看到的，有许多不同类型的层，但最常见的一种是全连接（或密集）层，它将层中的所有单元直接连接到前一层中的每个单元。


MLP

所有相邻层完全连接fully
connected的神经网络称为多层感知器（MLP）


学习高级特征

神经网络如此强大的关键特性是它们能够在没有人类指导的情况下从输入数据中学习特征。

单元A接收输入像素的单个通道的值。
单元B组合其输入值，以便在存在特定的低级特征（如边缘）时最强烈地触发。
单元C组合低级特征，以便在图像中看到更高级的特征（如牙齿）时最强烈地触发。
单元D组合高级特征，以便在原始图像中的人在微笑时最强烈地触发。


MLP的实践
TensorFlow &amp; Keras

TensorFlow 是一个用于机器学习的开源 Python 库，由 Google 开发。Keras
是一个用于构建神经网络的高级 API，构建在 TensorFlow 之上 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2024/01/20/informatique/deeplearning/Generative_1/" title="Chapter 1 Generative Modeling"><img class="post-bg" src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fgenerative.jpg" onerror="this.onerror=null;this.src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="Chapter 1 Generative Modeling"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/01/20/informatique/deeplearning/Generative_1/" title="Chapter 1 Generative Modeling">Chapter 1 Generative Modeling</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-01-20T15:19:05.000Z" title="发表于 2024-01-20 16:19:05">2024-01-20</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%94%9F%E6%88%90%E5%BC%8F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">学习笔记-生成式神经网络</a></span></div><div class="content">Chapter 1 Generative
Modeling

Generative modeling is a branch of machine learning that involves
training a model to produce new data that is similar to a given
dataset.

概念
深度学习模型
以生成与提供的数据集相似的新数据为目的的机械学习分支。

训练数据包含很多例子，其中每一个数据点被称为一个观察
observation
每个观察包含很多特征 feature
我们的目标是构建一个模型，该模型可以生成新的特征集，这些特征集看起来就像是使用与原始数据相同的规则创建的。
生成式模型应该是概率的probabilistic 而不是确定的deterministic

与判别式模型的区别

判别式模型预测\(p(y \mid x)\)
生成式模型预测\(p(x)\)，或者在一定情况下预测\(p(x|y)\)

For example, if our dataset contains d ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/10/#content-inner"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/#content-inner">10</a><span class="page-number current">11</span><a class="page-number" href="/page/12/#content-inner">12</a><span class="space">&hellip;</span><a class="page-number" href="/page/15/#content-inner">15</a><a class="extend next" rel="next" href="/page/12/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Fe747243b42e6168d02fdf8bccbbd4ea.jpg" onerror="this.onerror=null;this.src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffriend_404.gif'" alt="avatar"/></div><div class="author-info__name">Raphael Hyaan</div><div class="author-info__description">何日可谓归去来</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">150</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">49</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">18</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/raphaelhyaan"><i class="fab fa-github"></i><span>Bonjour</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/raphaelhyaan" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:raphael.ma.yuhan@outlook.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">仰观宇宙之大，俯察品类之盛</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/01/09/informatique/java/java-03-03/" title="J03 Java基础 03：集合框架"><img src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fanon cat 006.png" onerror="this.onerror=null;this.src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="J03 Java基础 03：集合框架"/></a><div class="content"><a class="title" href="/2025/01/09/informatique/java/java-03-03/" title="J03 Java基础 03：集合框架">J03 Java基础 03：集合框架</a><time datetime="2025-01-09T21:13:07.000Z" title="发表于 2025-01-09 22:13:07">2025-01-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/01/09/informatique/java/java-03-02/" title="J03 Java基础 02：面向对象"><img src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fanon cat 006.png" onerror="this.onerror=null;this.src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="J03 Java基础 02：面向对象"/></a><div class="content"><a class="title" href="/2025/01/09/informatique/java/java-03-02/" title="J03 Java基础 02：面向对象">J03 Java基础 02：面向对象</a><time datetime="2025-01-09T21:13:06.000Z" title="发表于 2025-01-09 22:13:06">2025-01-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/01/09/informatique/java/java-03-01/" title="J03 Java基础 01：基本语法"><img src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fanon cat 006.png" onerror="this.onerror=null;this.src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="J03 Java基础 01：基本语法"/></a><div class="content"><a class="title" href="/2025/01/09/informatique/java/java-03-01/" title="J03 Java基础 01：基本语法">J03 Java基础 01：基本语法</a><time datetime="2025-01-09T21:13:04.000Z" title="发表于 2025-01-09 22:13:04">2025-01-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/01/09/informatique/java/java-02/" title="J02 统一建模语言 UML"><img src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fanon cat 006.png" onerror="this.onerror=null;this.src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="J02 统一建模语言 UML"/></a><div class="content"><a class="title" href="/2025/01/09/informatique/java/java-02/" title="J02 统一建模语言 UML">J02 统一建模语言 UML</a><time datetime="2025-01-09T21:13:03.000Z" title="发表于 2025-01-09 22:13:03">2025-01-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/01/09/informatique/java/java-01/" title="J01 引言：面向对象和程序设计"><img src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fanon cat 006.png" onerror="this.onerror=null;this.src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="J01 引言：面向对象和程序设计"/></a><div class="content"><a class="title" href="/2025/01/09/informatique/java/java-01/" title="J01 引言：面向对象和程序设计">J01 引言：面向对象和程序设计</a><time datetime="2025-01-09T21:13:02.000Z" title="发表于 2025-01-09 22:13:02">2025-01-09</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            <a class="card-more-btn" href="/categories/" title="查看更多">
    <i class="fas fa-angle-right"></i></a>
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E4%BF%AF%E5%AF%9F%E5%93%81%E7%B1%BB%E4%B9%8B%E7%9B%9B/"><span class="card-category-list-name">俯察品类之盛</span><span class="card-category-list-count">9</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B9%90%E7%90%86%E5%92%8C%E5%90%89%E4%BB%96/"><span class="card-category-list-name">学习笔记-乐理和吉他</span><span class="card-category-list-count">5</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/"><span class="card-category-list-name">学习笔记-信号处理</span><span class="card-category-list-count">6</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%8A%A8%E6%80%81%E7%B3%BB%E7%BB%9F%E6%8E%A7%E5%88%B6/"><span class="card-category-list-name">学习笔记-动态系统控制</span><span class="card-category-list-count">5</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%B7%A5%E8%89%BA%E5%8C%96%E5%AD%A6-%E4%BC%A0%E7%83%AD%E5%AD%A6/"><span class="card-category-list-name">学习笔记-工艺化学/传热学</span><span class="card-category-list-count">5</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%A6%82%E7%8E%87%E7%BB%9F%E8%AE%A1/"><span class="card-category-list-name">学习笔记-概率统计</span><span class="card-category-list-count">7</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%B1%BD%E8%BD%A6%E8%87%AA%E5%8A%A8%E5%8C%96%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%8C%96/"><span class="card-category-list-name">学习笔记-汽车自动化与信息化</span><span class="card-category-list-count">11</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%83%AD%E5%8A%9B%E5%AD%A6%E5%BE%AA%E7%8E%AF/"><span class="card-category-list-name">学习笔记-热力学循环</span><span class="card-category-list-count">14</span></a></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/%E6%A4%8D%E7%89%A9/" style="font-size: 1.13em; color: #999a9c">植物</a> <a href="/tags/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/" style="font-size: 1.4em; color: #99a5b6">课程笔记</a> <a href="/tags/%E6%A6%82%E7%8E%87/" style="font-size: 1.1em; color: #999">概率</a> <a href="/tags/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/" style="font-size: 1.17em; color: #999c9f">毕业设计</a> <a href="/tags/%E5%8E%8B%E7%BC%A9%E4%B8%8E%E9%99%8D%E5%99%AA/" style="font-size: 1.17em; color: #999c9f">压缩与降噪</a> <a href="/tags/%E6%B3%95%E8%AF%AD/" style="font-size: 1.13em; color: #999a9c">法语</a> <a href="/tags/%E7%89%A9%E7%90%86/" style="font-size: 1.13em; color: #999a9c">物理</a> <a href="/tags/%E8%A7%81%E9%97%BB/" style="font-size: 1.13em; color: #999a9c">见闻</a> <a href="/tags/%E4%BC%A0%E7%83%AD/" style="font-size: 1.13em; color: #999a9c">传热</a> <a href="/tags/torch/" style="font-size: 1.1em; color: #999">torch</a> <a href="/tags/%E5%8A%A8%E6%80%81%E7%B3%BB%E7%BB%9F%E6%8E%A7%E5%88%B6/" style="font-size: 1.23em; color: #999ea6">动态系统控制</a> <a href="/tags/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/" style="font-size: 1.1em; color: #999">项目管理</a> <a href="/tags/%E6%B1%BD%E8%BD%A6%E8%87%AA%E5%8A%A8%E5%8C%96%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%8C%96/" style="font-size: 1.37em; color: #99a4b2">汽车自动化与信息化</a> <a href="/tags/%E5%B7%A5%E8%89%BA%E5%8C%96%E5%AD%A6/" style="font-size: 1.17em; color: #999c9f">工艺化学</a> <a href="/tags/%E7%A8%8B%E5%BA%8F/" style="font-size: 1.1em; color: #999">程序</a> <a href="/tags/%E5%A4%A7%E4%BD%9C%E4%B8%9A/" style="font-size: 1.1em; color: #999">大作业</a> <a href="/tags/%E7%83%AD%E5%8A%9B%E5%AD%A6/" style="font-size: 1.43em; color: #99a6b9">热力学</a> <a href="/tags/%E6%80%BB%E8%A7%88/" style="font-size: 1.27em; color: #99a0a9">总览</a> <a href="/tags/%E4%B9%90%E7%90%86%E5%92%8C%E5%90%89%E4%BB%96/" style="font-size: 1.23em; color: #999ea6">乐理和吉他</a> <a href="/tags/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/" style="font-size: 1.23em; color: #999ea6">面向对象</a> <a href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" style="font-size: 1.5em; color: #99a9bf">学习笔记</a> <a href="/tags/java/" style="font-size: 1.23em; color: #999ea6">java</a> <a href="/tags/%E5%B7%B4%E9%BB%8E%E5%8A%A8%E7%89%A9/" style="font-size: 1.2em; color: #999da3">巴黎动物</a> <a href="/tags/%E7%BB%8F%E6%B5%8E/" style="font-size: 1.3em; color: #99a1ac">经济</a> <a href="/tags/%E5%B7%B2%E5%88%A0%E9%99%A4/" style="font-size: 1.1em; color: #999">已删除</a> <a href="/tags/%E6%B3%95%E5%BE%8B/" style="font-size: 1.17em; color: #999c9f">法律</a> <a href="/tags/%E6%9F%8F%E6%9E%97%E5%8A%A8%E7%89%A9/" style="font-size: 1.1em; color: #999">柏林动物</a> <a href="/tags/%E7%BB%9F%E8%AE%A1%E7%89%A9%E7%90%86/" style="font-size: 1.27em; color: #99a0a9">统计物理</a> <a href="/tags/%E4%BE%8B%E5%AD%90/" style="font-size: 1.13em; color: #999a9c">例子</a> <a href="/tags/%E5%B7%B4%E9%BB%8E%E6%A4%8D%E7%89%A9/" style="font-size: 1.13em; color: #999a9c">巴黎植物</a> <a href="/tags/DCGAN/" style="font-size: 1.1em; color: #999">DCGAN</a> <a href="/tags/%E9%80%BB%E8%BE%91%E7%B3%BB%E7%BB%9F/" style="font-size: 1.33em; color: #99a2af">逻辑系统</a> <a href="/tags/%E9%87%8F%E5%AD%90%E5%8A%9B%E5%AD%A6/" style="font-size: 1.47em; color: #99a8bc">量子力学</a> <a href="/tags/%E6%95%B0%E5%AD%A6/" style="font-size: 1.1em; color: #999">数学</a> <a href="/tags/%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/" style="font-size: 1.27em; color: #99a0a9">信号处理</a> <a href="/tags/%E6%A6%82%E7%8E%87%E7%BB%9F%E8%AE%A1/" style="font-size: 1.27em; color: #99a0a9">概率统计</a> <a href="/tags/%E9%B8%9F%E7%BA%B2/" style="font-size: 1.13em; color: #999a9c">鸟纲</a> <a href="/tags/esp32/" style="font-size: 1.17em; color: #999c9f">esp32</a> <a href="/tags/%E7%BB%9F%E8%AE%A1/" style="font-size: 1.1em; color: #999">统计</a> <a href="/tags/%E6%9D%82%E8%AE%B0/" style="font-size: 1.2em; color: #999da3">杂记</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span><a class="card-more-btn" href="/archives/" title="查看更多">
    <i class="fas fa-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/01/"><span class="card-archive-list-date">一月 2025</span><span class="card-archive-list-count">5</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/12/"><span class="card-archive-list-date">十二月 2024</span><span class="card-archive-list-count">8</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/11/"><span class="card-archive-list-date">十一月 2024</span><span class="card-archive-list-count">22</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/10/"><span class="card-archive-list-date">十月 2024</span><span class="card-archive-list-count">7</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/09/"><span class="card-archive-list-date">九月 2024</span><span class="card-archive-list-count">5</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/08/"><span class="card-archive-list-date">八月 2024</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/07/"><span class="card-archive-list-date">七月 2024</span><span class="card-archive-list-count">5</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/06/"><span class="card-archive-list-date">六月 2024</span><span class="card-archive-list-count">11</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">150</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2025-01-09T21:22:13.999Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By Raphael Hyaan</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="framework-info"><span>备案号: </span><a href="href=&quot;https://beian.miit.gov.cn/&quot; ">京ICP备2024051904号</a><span class="footer-separator">|</span><img src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2F%E5%A4%87%E6%A1%88%E5%9B%BE%E6%A0%87.png" alt="MIT License" height="20" align="top"/><span> </span><a href="href=&quot;https://beian.mps.gov.cn/#/query/webSearch?code=11010802044068&quot; ">京公网安备11010802044068号</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>window.typedJSFn = {
  init: (str) => {
    window.typed = new Typed('#subtitle', Object.assign({
      strings: str,
      startDelay: 300,
      typeSpeed: 150,
      loop: true,
      backSpeed: 50,
    }, null))
  },
  run: (subtitleType) => {
    if (true) {
      if (typeof Typed === 'function') {
        subtitleType()
      } else {
        getScript('https://cdn.jsdelivr.net/npm/typed.js/dist/typed.umd.min.js').then(subtitleType)
      }
    } else {
      subtitleType()
    }
  }
}
</script><script>function subtitleType () {
  if (true) {
    typedJSFn.init(["自由自在"])
  } else {
    document.getElementById("subtitle").textContent = "自由自在"
  }
}
typedJSFn.run(subtitleType)</script></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>