<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>DCGAN | Raphael's Home</title><meta name="author" content="Raphael Hyaan"><meta name="copyright" content="Raphael Hyaan"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="DCGAN">
<meta property="og:type" content="article">
<meta property="og:title" content="DCGAN">
<meta property="og:url" content="http://raphaelhyaan.cn/2023/11/22/others/DCGAN-1/index.html">
<meta property="og:site_name" content="Raphael&#39;s Home">
<meta property="og:description" content="DCGAN">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FDCGAN%2FUntitled.png">
<meta property="article:published_time" content="2023-11-22T14:53:05.000Z">
<meta property="article:modified_time" content="2023-12-31T02:55:18.000Z">
<meta property="article:author" content="Raphael Hyaan">
<meta property="article:tag" content="学习笔记">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="毕业设计">
<meta property="article:tag" content="计算机">
<meta property="article:tag" content="DCGAN">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FDCGAN%2FUntitled.png"><link rel="shortcut icon" href="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Flana cat 002.png"><link rel="canonical" href="http://raphaelhyaan.cn/2023/11/22/others/DCGAN-1/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'DCGAN',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-12-31 10:55:18'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/butterflyChange/css/code.css"><meta name="generator" content="Hexo 7.0.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2FR-2.png" onerror="onerror=null;src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffriend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">179</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">59</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">21</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/Reading/"><i class="fa-fw fas fa-book"></i><span> Reading</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> Gallery</span></a></li><li><a class="site-page child" href="/Video/"><i class="fa-fw fas fa-video"></i><span> Video</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FDCGAN%2FUntitled.png')"><nav id="nav"><span id="blog-info"><a href="/" title="Raphael's Home"><span class="site-name">Raphael's Home</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/Reading/"><i class="fa-fw fas fa-book"></i><span> Reading</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> Gallery</span></a></li><li><a class="site-page child" href="/Video/"><i class="fa-fw fas fa-video"></i><span> Video</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">DCGAN</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-11-22T14:53:05.000Z" title="发表于 2023-11-22 22:53:05">2023-11-22</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-12-31T02:55:18.000Z" title="更新于 2023-12-31 10:55:18">2023-12-31</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%9B%B6%E6%95%A3%E7%AC%94%E8%AE%B0/">零散笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="DCGAN"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="dcgan">DCGAN</h1>
<p>Created: November 22, 2023 3:27 PM Class: 第七学期 Type: Quick Study
Reviewed: No Status: Not started</p>
<blockquote>
<p>本文参考pyTorch的相应教程快速实践生成式对抗神经网络</p>
</blockquote>
<p><a
target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html">DCGAN
Tutorial — PyTorch Tutorials 2.1.1+cu121 documentation</a></p>
<blockquote>
<p>尝试实现的代码可以在以下链接找到，实际上与原文提供的代码基本完全相同：</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://github.com/RaphaelHyaan/GAN_etude">GitHub -
RaphaelHyaan/GAN_etude: 学习使用GAN网络</a></p>
<p>本文很多内容是对此文章的拙略翻译</p>
<h1 id="简介">简介</h1>
<p>本教程将通过一个例子介绍DCGANs。我们将训练一个生成对抗网络(GAN)来生成新的名人，前提是向它展示了许多真实名人的照片。这里的大部分代码来自于<a
target="_blank" rel="noopener" href="https://github.com/pytorch/examples">pytorch/examples</a>中的DCGAN实现，本文将详细解释实现，并阐明这个模型如何以及为什么工作。但是，不用担心，无需事先了解GANs，但是初学者可能需要花一些时间来推理实际上在底层发生了什么。另外，为了节省时间，最好有一个或两个GPU。让我们从头开始。</p>
<h1 id="生成对抗网络">生成对抗网络</h1>
<h2 id="什么是gan">什么是GAN？</h2>
<ul>
<li>GANs是一个框架，用于教授深度学习模型如何捕获训练数据分布，以便我们可以从同一分布中生成新数据。GANs由Ian
Goodfellow于2014年发明，并首次在<a
target="_blank" rel="noopener" href="https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf">生成对抗网络</a>一文中描述。</li>
<li>它们由两个不同的模型组成，一个<em>生成器</em>和一个<em>鉴别器</em>。
<ul>
<li>生成器的任务是生成看起来像训练图像的‘假’图像。</li>
<li>鉴别器的任务是查看图像并输出它是否是来自生成器的真实训练图像或假图像。</li>
</ul></li>
<li>在训练过程中，生成器不断尝试通过生成越来越好的假图像来智胜鉴别器，而鉴别器则努力成为更好的侦探，正确地分类真实和假图像。</li>
<li>这个游戏的平衡点是生成器生成的假图像看起来就像直接来自训练数据，而鉴别器则总是以50%的信心猜测生成器的输出是真实还是假的。</li>
</ul>
<h2 id="符号定义">符号定义</h2>
<h3 id="鉴别器"><strong>鉴别器</strong></h3>
<ul>
<li>现在，让我们定义一些在整个教程中使用的符号，从鉴别器开始。设<span
class="math inline">\(x\)</span>为表示图像的数据。<span
class="math inline">\(D(x)\)</span>是鉴别器网络，它输出<span
class="math inline">\(x\)</span>来自训练数据而不是生成器的（标量）概率。</li>
<li>在这里，由于我们正在处理图像，所以<span
class="math inline">\(D(x)\)</span>的输入是CHW大小3x64x64的图像。</li>
<li>直观地说，当<span
class="math inline">\(x\)</span>来自训练数据时，<span
class="math inline">\(D(x)\)</span>应该是<strong><code>HIGH</code></strong>，当<span
class="math inline">\(x\)</span>来自生成器时，应该是<code>**LOW**</code>。<span
class="math inline">\(D(x)\)</span>也可以被视为传统的二元分类器。</li>
</ul>
<h3 id="生成器"><strong>生成器</strong></h3>
<ul>
<li>对于生成器的符号，设<span
class="math inline">\(z\)</span>是一个从标准正态分布中采样的<strong>潜在空间向量</strong>。<span
class="math inline">\(G(z)\)</span>表示生成器函数，它将潜在向量<span
class="math inline">\(z\)</span>映射到数据空间。<span
class="math inline">\(G\)</span>的目标是<strong>估计训练数据来自的分布</strong><span
class="math inline">\((p_{data})\)</span>，以便它可以从该估计分布（<span
class="math inline">\(P_g\)</span>）生成假样本。</li>
</ul>
<p>因此，<span class="math inline">\(D(G(z))\)</span>是生成器<span
class="math inline">\(G\)</span>的输出是真实图像的概率（标量）。</p>
<p>如<a
target="_blank" rel="noopener" href="https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf">Goodfellow的论文</a>所述，<span
class="math inline">\(D\)</span>和<span
class="math inline">\(G\)</span>:</p>
<ul>
<li><span
class="math inline">\(D\)</span>试图最大化正确分类真实和假的概率<span
class="math inline">\((logD(x))\)</span></li>
<li><span class="math inline">\(G\)</span>试图最小化<span
class="math inline">\(D\)</span>预测其输出是假的概率<span
class="math inline">\((1-log(D(x)))\)</span></li>
<li>从论文中，GAN的损失函数是</li>
</ul>
<p><span class="math display">\[
min_Gmax_DV(D,G)=E_{x∼pdata(x)}[logD(x)]+E_{z∼pz(z)}[log(1−D(G(z)))]
\]</span></p>
<p>理论上，这个极小极大游戏的解是<span class="math inline">\(p_g =
p_{data}\)</span>，并且鉴别器随机猜测输入是真实还是假的。然而，GAN的收敛理论仍在积极研究中，实际上模型并不总是训练到这一点。</p>
<h2 id="什么是dcgan">什么是DCGAN？</h2>
<p>DCGAN是上述GAN的直接扩展，不同之处在于它在鉴别器和生成器中明确使用了卷积和卷积转置层。它首次由Radford等人在论文<a
target="_blank" rel="noopener" href="https://arxiv.org/pdf/1511.06434.pdf">无监督表示学习与深度卷积生成对抗网络</a>中描述。</p>
<ul>
<li>鉴别器由分步<a
target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d">卷积</a>层，<a
target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/nn.html#torch.nn.BatchNorm2d">批量标准化</a>层，和<a
target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/nn.html#torch.nn.LeakyReLU">LeakyReLU</a>激活组成。输入是3x64x64的输入图像，输出是输入来自真实数据分布的标量概率。</li>
<li>生成器由<a
target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/nn.html#torch.nn.ConvTranspose2d">卷积转置</a>层，批量标准化层和<a
target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/nn.html#relu">ReLU</a>激活组成。输入是从标准正态分布中抽取的潜在向量<span
class="math inline">\(z\)</span>，输出是3x64x64的RGB图像。分步卷积转置层允许潜在向量被转换为与图像相同形状的体积。</li>
<li>在论文中，作者还给出了一些关于如何设置优化器，如何计算损失函数，以及如何初始化模型权重的提示，所有这些将在接下来的部分中解释。</li>
</ul>
<p><img
src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FDCGAN%2FUntitled.png" /></p>
<h1 id="输入">输入</h1>
<p>定义一些运行的输入：</p>
<ul>
<li><code>dataroot</code> -
数据集文件夹的根路径。我们将在下一节详细讨论数据集。</li>
<li><code>workers</code> -
用于通过<code>DataLoader</code>加载数据的工作线程数。</li>
<li><code>batch_size</code> -
训练中使用的批次大小。DCGAN论文使用的批次大小为128。</li>
<li><code>image_size</code> -
用于训练的图像的空间大小。此实现默认为64x64。如果需要其他大小，必须改变D和G的结构。具体详情请看<a
target="_blank" rel="noopener" href="https://github.com/pytorch/examples/issues/70">这里</a>。</li>
<li><code>nc</code> - 输入图像的颜色通道数量。对于彩色图像，这是3。</li>
<li><code>nz</code> - 潜在向量的长度。</li>
<li><code>ngf</code> - 与通过生成器传输的特征图的深度有关。</li>
<li><code>ndf</code> - 设置通过鉴别器传播的特征图的深度。</li>
<li><code>num_epochs</code> -
运行的训练时期数。更长时间的训练可能会导致更好的结果，但也需要更长的时间。</li>
<li><code>lr</code> -
训练的学习率。如DCGAN论文所描述，这个数字应为0.0002。</li>
<li><code>beta1</code> -
Adam优化器的beta1超参数。如论文所述，这个数应为0.5。</li>
<li><code>ngpu</code> -
可用的GPU数量。如果这个数为0，代码将在CPU模式下运行。如果这个数大于0，它将在该数量的GPU上运行。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 参数设置</span></span><br><span class="line"><span class="comment"># 根路径</span></span><br><span class="line">dataroot = <span class="string">&quot;data/celeba&quot;</span></span><br><span class="line"><span class="comment"># 加载数据的线程数</span></span><br><span class="line">workers = <span class="number">2</span></span><br><span class="line"><span class="comment"># 批次大小</span></span><br><span class="line">batch_size = <span class="number">128</span></span><br><span class="line"><span class="comment"># 训练图像的空间大小</span></span><br><span class="line"><span class="comment">#   size using a transformer.</span></span><br><span class="line">image_size = <span class="number">64</span></span><br><span class="line"><span class="comment"># 颜色通道数</span></span><br><span class="line">nc = <span class="number">3</span></span><br><span class="line"><span class="comment"># 潜在向量长度</span></span><br><span class="line">nz = <span class="number">100</span></span><br><span class="line"><span class="comment"># 生成器中的特征图大小</span></span><br><span class="line">ngf = <span class="number">64</span></span><br><span class="line"><span class="comment"># 判别器中的特征图大小</span></span><br><span class="line">ndf = <span class="number">64</span></span><br><span class="line"><span class="comment"># 训练周期数</span></span><br><span class="line">num_epochs = <span class="number">5</span></span><br><span class="line"><span class="comment"># 学习率</span></span><br><span class="line">lr = <span class="number">0.0002</span></span><br><span class="line"><span class="comment"># Adam 优化器的 beta1 超参数</span></span><br><span class="line">beta1 = <span class="number">0.5</span></span><br><span class="line"><span class="comment"># GPU 数量。使用 0 可以在 CPU 模式下运行。</span></span><br><span class="line">ngpu = <span class="number">1</span></span><br></pre></td></tr></table></figure>
<h1 id="数据">数据</h1>
<p>在这个教程中，我们将使用 <a
target="_blank" rel="noopener" href="http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html">Celeb-A Faces
数据集</a>，您可以在链接的网站上下载，或者在 <a
target="_blank" rel="noopener" href="https://drive.google.com/drive/folders/0B7EVK8r0v71pTUZsaXdaSnZBZzg">Google
Drive</a> 中下载。下载的数据集将以 <code>img_align_celeba.zip</code>
的文件名下载。下载后，创建一个名为 <code>celeba</code> 的目录，并将 zip
文件解压缩到该目录中。然后，将这个笔记本的 <code>dataroot</code>
输入设置为您刚刚创建的 <code>celeba</code>
目录。最终的目录结构应如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">/path/to/celeba</span><br><span class="line">    -&gt; img_align_celeba</span><br><span class="line">        -&gt; <span class="number">188242.j</span>pg</span><br><span class="line">        -&gt; <span class="number">173822.j</span>pg</span><br><span class="line">        -&gt; <span class="number">284702.j</span>pg</span><br><span class="line">        -&gt; <span class="number">537394.j</span>pg</span><br><span class="line">           ...</span><br></pre></td></tr></table></figure>
<p>这是一个重要的步骤，因为我们将使用 <code>ImageFolder</code>
数据集类，它要求数据集根文件夹中有子目录。现在，我们可以创建数据集，创建数据加载器，设置运行设备，最后可视化一些训练数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 我们可以使用设置好的图像文件夹数据集。</span></span><br><span class="line"><span class="comment"># 创建数据集</span></span><br><span class="line">dataset = dset.ImageFolder(root=dataroot,</span><br><span class="line">                           transform=transforms.Compose([</span><br><span class="line">                               transforms.Resize(image_size),</span><br><span class="line">                               transforms.CenterCrop(image_size),</span><br><span class="line">                               transforms.ToTensor(),</span><br><span class="line">                               transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>)),</span><br><span class="line">                           ]))</span><br><span class="line"><span class="comment"># 创建数据加载器</span></span><br><span class="line">dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,</span><br><span class="line">                                         shuffle=<span class="literal">True</span>, num_workers=workers)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 决定我们要在哪个设备上运行</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> (torch.cuda.is_available() <span class="keyword">and</span> ngpu &gt; <span class="number">0</span>) <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制一些训练图像</span></span><br><span class="line">real_batch = <span class="built_in">next</span>(<span class="built_in">iter</span>(dataloader))</span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">8</span>))</span><br><span class="line">plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Training Images&quot;</span>)</span><br><span class="line">plt.imshow(np.transpose(vutils.make_grid(real_batch[<span class="number">0</span>].to(device)[:<span class="number">64</span>], padding=<span class="number">2</span>, normalize=<span class="literal">True</span>).cpu(),(<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>)))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>显示效果：</p>
<p><img
src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FDCGAN%2FFigure_1.png" /></p>
<h1 id="实施">实施</h1>
<p>设置了输入参数并准备好了数据集后，我们现在可以开始实施了。我们将从权重初始化策略开始，然后详细讨论生成器、鉴别器、损失函数和训练循环。</p>
<h2 id="权重初始化">权重初始化</h2>
<p>从DCGAN论文中，作者指定所有模型权重应从均值为0、标准差为0.02的正态分布中随机初始化。<code>weights_init</code>函数接受一个初始化的模型作为输入，并重新初始化所有卷积、卷积转置和批量标准化层以满足这一标准。这个函数在模型初始化后立即应用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 自定义权重初始化函数，用于初始化“netG”和“netD”</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">weights_init</span>(<span class="params">m</span>):</span><br><span class="line">    classname = m.__class__.__name__</span><br><span class="line">    <span class="keyword">if</span> classname.find(<span class="string">&#x27;Conv&#x27;</span>) != -<span class="number">1</span>:</span><br><span class="line">        nn.init.normal_(m.weight.data, <span class="number">0.0</span>, <span class="number">0.02</span>)</span><br><span class="line">    <span class="keyword">elif</span> classname.find(<span class="string">&#x27;BatchNorm&#x27;</span>) != -<span class="number">1</span>:</span><br><span class="line">        nn.init.normal_(m.weight.data, <span class="number">1.0</span>, <span class="number">0.02</span>)</span><br><span class="line">        nn.init.constant_(m.bias.data, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h2 id="生成器-1">生成器</h2>
<ul>
<li><p>生成器 <span class="math inline">\(G\)</span>
的设计目的是将潜在空间向量 <span class="math inline">\((z)\)</span>
映射到数据空间。由于我们的数据是图像，因此将 <span
class="math inline">\(z\)</span>
转换为数据空间意味着最终创建与训练图像相同大小的RGB图像（即<code>3x64x64</code>）。</p></li>
<li><p>在实践中，这是通过一系列步距为2的二维卷积转置层来完成的，每个层都配对一个2d批量归一化层和一个relu激活函数。</p></li>
<li><p>生成器的输出通过tanh函数进行处理，以将其返回到输入数据范围[−1,1]。</p></li>
<li><p>卷积转置层后存在批量归一化函数，这是DCGAN论文的关键贡献。这些层有助于在训练期间梯度的流动。以下是来自DCGAN论文的生成器图像。</p>
<p><img
src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FDCGAN%2Fdcgan_generator.png" /></p></li>
</ul>
<p>请注意，我们在输入部分设置的输入（<code>nz</code>，<code>ngf</code>和<code>nc</code>）如何在代码中影响生成器架构。<code>nz</code>是z输入向量的长度，<code>ngf</code>与通过生成器传播的特征图的大小有关，而<code>nc</code>是输出图像中的通道数量（设置为3以获取RGB图像）。以下是生成器的代码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Generator 代码</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Generator</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, ngpu</span>):</span><br><span class="line">        <span class="built_in">super</span>(Generator, self).__init__()</span><br><span class="line">        self.ngpu = ngpu</span><br><span class="line">        self.main = nn.Sequential(</span><br><span class="line">            <span class="comment"># 输入是Z，进入一个卷积转置层</span></span><br><span class="line">            nn.ConvTranspose2d( nz, ngf * <span class="number">8</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">0</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(ngf * <span class="number">8</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># 状态大小。``(ngf*8) x 4 x 4``</span></span><br><span class="line">            nn.ConvTranspose2d(ngf * <span class="number">8</span>, ngf * <span class="number">4</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(ngf * <span class="number">4</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># 状态大小。``(ngf*4) x 8 x 8``</span></span><br><span class="line">            nn.ConvTranspose2d( ngf * <span class="number">4</span>, ngf * <span class="number">2</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(ngf * <span class="number">2</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># 状态大小。``(ngf*2) x 16 x 16``</span></span><br><span class="line">            nn.ConvTranspose2d( ngf * <span class="number">2</span>, ngf, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(ngf),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># 状态大小。``(ngf) x 32 x 32``</span></span><br><span class="line">            nn.ConvTranspose2d( ngf, nc, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.Tanh()</span><br><span class="line">            <span class="comment"># 状态大小。``(nc) x 64 x 64``</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span></span>):</span><br><span class="line">        <span class="keyword">return</span> self.main(<span class="built_in">input</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>现在，我们可以实例化生成器并应用 <code>weights_init</code>
函数。查看打印的模型以查看生成器对象的结构。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建生成器</span></span><br><span class="line">netG = Generator(ngpu).to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果需要，处理多GPU</span></span><br><span class="line"><span class="keyword">if</span> (device.<span class="built_in">type</span> == <span class="string">&#x27;cuda&#x27;</span>) <span class="keyword">and</span> (ngpu &gt; <span class="number">1</span>):</span><br><span class="line">    netG = nn.DataParallel(netG, <span class="built_in">list</span>(<span class="built_in">range</span>(ngpu)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将 &quot;weights_init&quot; 函数应用于随机初始化所有权重</span></span><br><span class="line"><span class="comment"># 为 &quot;mean=0&quot;, &quot;stdev=0.02&quot;.</span></span><br><span class="line">netG.apply(weights_init)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印模型</span></span><br><span class="line"><span class="built_in">print</span>(netG)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="鉴别器-1">鉴别器</h2>
<p>如前所述，鉴别器 <strong>D</strong>
是一个二元分类网络，其输入是一张图片，输出是输入图片为真（相对于假）的概率。在这里，<strong>D</strong>
接收一张3x64x64的输入图像，通过一系列的 Conv2d, BatchNorm2d, 和
LeakyReLU 层处理它，并通过 Sigmoid
激活函数输出最后的概率。如果问题需要，可以扩展这个体系结构的更多层，但是
strided 卷积，BatchNorm，和 LeakyReLUs 的使用有其重要性。DCGAN
论文提到，使用 strided
卷积而不是池化进行下采样是一种好的实践，因为它让网络学习自己的池化函数。同时，批量标准化和
leaky relu 函数促进了健康的梯度流动，这对于 <strong>G</strong> 和
<strong>D</strong> 的学习过程至关重要。</p>
<h3 id="鉴别器代码"><strong>鉴别器代码</strong></h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Discriminator</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, ngpu</span>):</span><br><span class="line">        <span class="built_in">super</span>(Discriminator, self).__init__()</span><br><span class="line">        self.ngpu = ngpu</span><br><span class="line">        self.main = nn.Sequential(</span><br><span class="line">            <span class="comment"># 输入是 ``(nc) x 64 x 64``</span></span><br><span class="line">            nn.Conv2d(nc, ndf, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># 状态大小. ``(ndf) x 32 x 32``</span></span><br><span class="line">            nn.Conv2d(ndf, ndf * <span class="number">2</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(ndf * <span class="number">2</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># 状态大小. ``(ndf*2) x 16 x 16``</span></span><br><span class="line">            nn.Conv2d(ndf * <span class="number">2</span>, ndf * <span class="number">4</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(ndf * <span class="number">4</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># 状态大小. ``(ndf*4) x 8 x 8``</span></span><br><span class="line">            nn.Conv2d(ndf * <span class="number">4</span>, ndf * <span class="number">8</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(ndf * <span class="number">8</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># 状态大小. ``(ndf*8) x 4 x 4``</span></span><br><span class="line">            nn.Conv2d(ndf * <span class="number">8</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">0</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span></span>):</span><br><span class="line">        <span class="keyword">return</span> self.main(<span class="built_in">input</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>现在，和生成器一样，我们可以创建鉴别器，应用
<code>weights_init</code> 函数，并打印模型的结构。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建鉴别器</span></span><br><span class="line">netD = Discriminator(ngpu).to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果需要，处理多GPU</span></span><br><span class="line"><span class="keyword">if</span> (device.<span class="built_in">type</span> == <span class="string">&#x27;cuda&#x27;</span>) <span class="keyword">and</span> (ngpu &gt; <span class="number">1</span>):</span><br><span class="line">    netD = nn.DataParallel(netD, <span class="built_in">list</span>(<span class="built_in">range</span>(ngpu)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 应用 ``weights_init`` 函数随机初始化所有权重</span></span><br><span class="line"><span class="comment"># 如下：``均值=0，标准偏差=0.2``。</span></span><br><span class="line">netD.apply(weights_init)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印模型</span></span><br><span class="line"><span class="built_in">print</span>(netD)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="损失函数和优化器">损失函数和优化器</h2>
<h3 id="损失函数">损失函数</h3>
<p>有了<span class="math inline">\(D\)</span>和<span
class="math inline">\(*G*\)</span>的设置，我们可以通过损失函数和优化器来指定他们的学习方式。我们将使用二元交叉熵损失（<a
target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#torch.nn.BCELoss">BCELoss</a>）函数，该函数在PyTorch中定义为：</p>
<p><span class="math display">\[
ℓ(x,y)=L=\{l_1,…,l_N\}^⊤,\ \ \ \ ln=−[y_n⋅logx_n+(1−y_n)⋅log(1−x_n)]
\]</span></p>
<ul>
<li>注意这个函数如何提供目标函数中的两个<span
class="math inline">\(log\)</span>组件的计算（即 <span
class="math inline">\(*log(D(x))*\)</span> 和 <span
class="math inline">\(*log(1−D(G(z)))*\)</span>）。我们可以通过 <span
class="math inline">\(*y*\)</span>
输入来指定使用BCE等式的哪一部分。这在即将出现的训练循环中实现，但了解我们如何通过改变
<span class="math inline">\(*y*\)</span>（即
GT标签）来选择要计算哪个组件是很重要的。</li>
</ul>
<h3 id="真假标签">真假标签</h3>
<p>接下来，我们定义我们的真实标签为1，假标签为0。这些标签将在计算 <span
class="math inline">\(D\)</span> 和 <span
class="math inline">\(*G*\)</span>
的损失时使用，这也是原始GAN论文中使用的约定。</p>
<h3 id="优化器">优化器</h3>
<p>最后，我们为 <span class="math inline">\(*D*\)</span> 和 <span
class="math inline">\(*G*\)</span> 分别设置两个独立的优化器。</p>
<ul>
<li>两者都是<span class="math inline">\(lr = 0.0002，Beta1 =
0.5\)</span>的Adam优化器。</li>
</ul>
<h3 id="噪音">噪音</h3>
<p>为了跟踪生成器的学习进度，我们将生成一批固定的从高斯分布中抽取的潜在向量（即
fixed_noise）。在训练循环中，我们会定期将这个fixed_noise输入到 <span
class="math inline">\(*G*\)</span>
中，随着迭代的进行，我们会看到图像从噪声中形成。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化 &quot;BCELoss&quot; 函数</span></span><br><span class="line">criterion = nn.BCELoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建我们将用来可视化生成器进展的潜在向量批次</span></span><br><span class="line">fixed_noise = torch.randn(<span class="number">64</span>, nz, <span class="number">1</span>, <span class="number">1</span>, device=device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在训练期间建立真实和假标签的约定</span></span><br><span class="line">real_label = <span class="number">1.</span></span><br><span class="line">fake_label = <span class="number">0.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 为G和D设置Adam优化器</span></span><br><span class="line">optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, <span class="number">0.999</span>))</span><br><span class="line">optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, <span class="number">0.999</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="训练">训练</h1>
<p>最后，既然我们已经定义了所有的GAN框架部分，我们可以开始训练它。</p>
<ul>
<li>要注意的是，训练GANs有点抽象，因为不正确的超参数设置会导致模式崩溃，而对于出了什么问题却鲜有解释。</li>
<li>在这里，我们将紧密遵循来自<a
target="_blank" rel="noopener" href="https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf">Goodfellow的论文</a>的算法1，同时遵守在<a
target="_blank" rel="noopener" href="https://github.com/soumith/ganhacks">ganhacks</a>中显示的一些最佳实践。</li>
<li>也就是说，我们将“为真实和假图像构造不同的小批量”，并将G的目标函数调整为最大化<span
class="math inline">\(*log(D(G(z)))*\)</span>。训练分为两个主要部分。第1部分更新鉴别器，第2部分更新生成器。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 训练循环</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 跟踪进度的列表</span></span><br><span class="line">img_list = []</span><br><span class="line">G_losses = []</span><br><span class="line">D_losses = []</span><br><span class="line">iters = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;开始训练循环...&quot;</span>)</span><br><span class="line"><span class="comment"># 对每一个训练周期</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="comment"># 对数据加载器中的每一批次</span></span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader, <span class="number">0</span>):</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="第1部分---训练鉴别器">第1部分 - 训练鉴别器</h2>
<p>训练鉴别器的目标是最大化正确地将给定输入分类<strong>为真实或假</strong>的概率。</p>
<ul>
<li>在Goodfellow的角度来看，我们希望“通过提升其随机梯度来更新鉴别器”。</li>
<li>实际上，我们希望最大化<span
class="math inline">\(*log(D(x))+log(1−D(G(z)))*\)</span>。</li>
<li>由于来自<a
target="_blank" rel="noopener" href="https://github.com/soumith/ganhacks">ganhacks</a>的单独小批量建议，我们将分两步计算这个。
<ul>
<li>首先，我们将从训练集中构造一个真实样本的批次，通过<span
class="math inline">\(*D*\)</span>进行前向传播，计算损失（<span
class="math inline">\(*log(D(x))*\)</span>），然后在一个反向传播中计算梯度。</li>
<li>其次，我们将使用当前的生成器构造一个假样本的批次，通过<span
class="math inline">\(*D*\)</span>对这个批次进行前向传播，计算损失（<span
class="math inline">\(*log(1−D(G(z)))*\)</span>），并在反向传播中累积梯度。</li>
</ul></li>
<li>现在，有了来自全部真实和全部假批次的梯度积累，我们调用鉴别器优化器的步骤。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">	<span class="comment">############################</span></span><br><span class="line">    <span class="comment"># (1) 更新D网络：最大化 log(D(x)) + log(1 - D(G(z)))</span></span><br><span class="line">    <span class="comment">###########################</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">#----------------------------</span></span><br><span class="line">    <span class="comment">## 使用全部真实批次进行训练</span></span><br><span class="line">    netD.zero_grad()</span><br><span class="line">    <span class="comment"># 格式化批次</span></span><br><span class="line">    real_cpu = data[<span class="number">0</span>].to(device)</span><br><span class="line">    b_size = real_cpu.size(<span class="number">0</span>)</span><br><span class="line">    label = torch.full((b_size,), real_label, dtype=torch.<span class="built_in">float</span>, device=device)</span><br><span class="line">    <span class="comment"># 通过D网络向前传递真实批次</span></span><br><span class="line">    output = netD(real_cpu).view(-<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 计算全部真实批次的损失</span></span><br><span class="line">    errD_real = criterion(output, label)</span><br><span class="line">    <span class="comment"># 在反向传递中计算D的梯度</span></span><br><span class="line">    errD_real.backward()</span><br><span class="line">    D_x = output.mean().item()</span><br><span class="line"><span class="comment">#----------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#----------------------------</span></span><br><span class="line">    <span class="comment">## 使用全部假批次进行训练</span></span><br><span class="line">    <span class="comment"># **生成潜在向量批次**</span></span><br><span class="line">    noise = torch.randn(b_size, nz, <span class="number">1</span>, <span class="number">1</span>, device=device)</span><br><span class="line">    <span class="comment"># 使用G生成假图像批次</span></span><br><span class="line">    fake = netG(noise)</span><br><span class="line">    label.fill_(fake_label)</span><br><span class="line">    <span class="comment"># 使用D对全部假批次进行分类</span></span><br><span class="line">    output = netD(fake.detach()).view(-<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 计算D在全部假批次上的损失</span></span><br><span class="line">    errD_fake = criterion(output, label)</span><br><span class="line">    <span class="comment"># 计算此批次的梯度，并与之前的梯度累计（求和）</span></span><br><span class="line">    errD_fake.backward()</span><br><span class="line">    D_G_z1 = output.mean().item()</span><br><span class="line"><span class="comment">#----------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#----------------------------</span></span><br><span class="line">    <span class="comment"># 计算D的误差，为假批次和真批次的误差之和</span></span><br><span class="line">    errD = errD_real + errD_fake</span><br><span class="line">    <span class="comment"># 更新D</span></span><br><span class="line">    optimizerD.step()</span><br><span class="line"><span class="comment">#----------------------------</span></span><br></pre></td></tr></table></figure>
<h2 id="第2部分---训练生成器">第2部分 - 训练生成器</h2>
<p>如原始论文所述，我们希望通过最小化<span
class="math inline">\(*log(1−D(G(z)))*\)</span>来训练生成器，以努力生成更好的假样本。如前所述，Goodfellow证明这并不能提供足够的梯度，特别是在学习过程的早期。</p>
<ul>
<li>作为一种修复方法，<strong>我们反而希望最大化</strong><span
class="math inline">\(*log(D(G(z)))*\)</span>。</li>
<li>在代码中，我们通过以下方式实现这一点：
<ul>
<li><strong>使用鉴别器对第1部分的生成器输出进行分类</strong></li>
<li><strong>使用真实标签作为GT来计算G的损失</strong></li>
<li>在反向传播中计算G的梯度</li>
<li>最后使用优化器步骤更新G的参数。</li>
</ul></li>
</ul>
<p>使用真实标签作为损失函数的GT标签可能看起来违反直觉【确实难以理解】，但这使我们能够使用<code>BCELoss</code>的<span
class="math inline">\(*log(x)*\)</span>部分（而不是<span
class="math inline">\(*log(1−x)*\)</span>部分），这正是我们想要的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">############################</span></span><br><span class="line"><span class="comment"># (2) 更新 G 网络: 最大化 log(D(G(z)))</span></span><br><span class="line"><span class="comment">###########################</span></span><br><span class="line">netG.zero_grad()</span><br><span class="line">label.fill_(real_label)  <span class="comment"># 对于生成器代价来说，假标签是真实的</span></span><br><span class="line"><span class="comment"># 由于我们刚刚更新了 D, 通过 D 执行全部假批次的另一个前向传递</span></span><br><span class="line">output = netD(fake).view(-<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 基于此输出计算 G 的损失</span></span><br><span class="line">errG = criterion(output, label)</span><br><span class="line"><span class="comment"># 为 G 计算梯度</span></span><br><span class="line">errG.backward()</span><br><span class="line">D_G_z2 = output.mean().item()</span><br><span class="line"><span class="comment"># 更新 G</span></span><br><span class="line">optimizerG.step()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="第3部分---统计报告">第3部分 - 统计报告</h2>
<p>最后，我们将进行一些统计报告，并在每个时期结束时，我们将通过生成器推动我们的固定噪声批次，以直观地跟踪G的训练进度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输出训练统计</span></span><br><span class="line"><span class="keyword">if</span> i % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f&#x27;</span></span><br><span class="line">          % (epoch, num_epochs, i, <span class="built_in">len</span>(dataloader),</span><br><span class="line">             errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存用于以后绘制的损失</span></span><br><span class="line">G_losses.append(errG.item())</span><br><span class="line">D_losses.append(errD.item())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过保存固定噪声上的G的输出检查生成器的表现如何</span></span><br><span class="line"><span class="keyword">if</span> (iters % <span class="number">500</span> == <span class="number">0</span>) <span class="keyword">or</span> ((epoch == num_epochs-<span class="number">1</span>) <span class="keyword">and</span> (i == <span class="built_in">len</span>(dataloader)-<span class="number">1</span>)):</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        fake = netG(fixed_noise).detach().cpu()</span><br><span class="line">    img_list.append(vutils.make_grid(fake, padding=<span class="number">2</span>, normalize=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line">iters += <span class="number">1</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>Loss_D - 判别器损失，计算为所有真实批次和所有假批次的损失之和<span
class="math inline">\(*log(D(x))+log(1−D(G(z)))）*\)</span>。</li>
<li>Loss_G - 生成器损失，计算为 <span
class="math inline">\(*log(D(G(z)))*\)</span>.</li>
<li>D(x) -
对所有真实批次的判别器的平均输出。这个数值应该从接近1开始，然后理论上当G变好时收敛到0.5。</li>
<li>D(G(z)) -
对所有假批次的判别器的平均输出。第一个数字是在更新D之前，第二个数字是在更新D之后。这些数值应该从接近0开始，然后当G变好时收敛到0.5。</li>
<li>两者收敛到0.5可能代表着生成器和判别器的性能相近</li>
</ul>
<h1 id="结果">结果</h1>
<p>最后，让我们看看我们的成果。这里，我们将看到三个不同的结果。</p>
<h3
id="在训练过程中d和g的损失是如何变化的">在训练过程中D和G的损失是如何变化的</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">5</span>))</span><br><span class="line">plt.title(<span class="string">&quot;Generator and Discriminator Loss During Training&quot;</span>)</span><br><span class="line">plt.plot(G_losses,label=<span class="string">&quot;G&quot;</span>)</span><br><span class="line">plt.plot(D_losses,label=<span class="string">&quot;D&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;iterations&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Loss&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h3
id="在每个周期上可视化g在固定噪声批次的输出">在每个周期上可视化G在固定噪声批次的输出</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure(figsize=(<span class="number">8</span>,<span class="number">8</span>))</span><br><span class="line">plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">ims = [[plt.imshow(np.transpose(i,(<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>)), animated=<span class="literal">True</span>)] <span class="keyword">for</span> i <span class="keyword">in</span> img_list]</span><br><span class="line">ani = animation.ArtistAnimation(fig, ims, interval=<span class="number">1000</span>, repeat_delay=<span class="number">1000</span>, blit=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">HTML(ani.to_jshtml())</span><br></pre></td></tr></table></figure>
<h3 id="一批真实数据和g的一批假数据">一批真实数据和G的一批假数据</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从数据加载器中获取一批真实的图片</span></span><br><span class="line">real_batch = <span class="built_in">next</span>(<span class="built_in">iter</span>(dataloader))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制真实的图片</span></span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>,<span class="number">15</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;真实的图片&quot;</span>)</span><br><span class="line">plt.imshow(np.transpose(vutils.make_grid(real_batch[<span class="number">0</span>].to(device)[:<span class="number">64</span>], padding=<span class="number">5</span>, normalize=<span class="literal">True</span>).cpu(),(<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从最后一轮绘制生成的假图片</span></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;假的图片&quot;</span>)</span><br><span class="line">plt.imshow(np.transpose(img_list[-<span class="number">1</span>],(<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>)))</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://raphaelhyaan.cn">Raphael Hyaan</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://raphaelhyaan.cn/2023/11/22/others/DCGAN-1/">http://raphaelhyaan.cn/2023/11/22/others/DCGAN-1/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://raphaelhyaan.cn" target="_blank">Raphael's Home</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><a class="post-meta__tags" href="/tags/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/">毕业设计</a><a class="post-meta__tags" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/">计算机</a><a class="post-meta__tags" href="/tags/DCGAN/">DCGAN</a></div><div class="post_share"></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/11/22/others/ase-io/" title="文件读写_ase_io"><img class="cover" src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Fcover%2F41524_2021_670_Fig2_HTML.webp" onerror="onerror=null;src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">文件读写_ase_io</div></div></a></div><div class="next-post pull-right"><a href="/2023/11/18/physique/EM/" title="电磁辐射波课程总览"><img class="cover" src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Fcover%2F%E7%94%B5%E7%A3%81%E5%AD%A6.png" onerror="onerror=null;src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">电磁辐射波课程总览</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/11/22/others/ase-atom/" title="Atom &amp; Atoms"><img class="cover" src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Fcover%2F41524_2021_670_Fig2_HTML.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-11-22</div><div class="title">Atom &amp; Atoms</div></div></a></div><div><a href="/2023/11/22/others/ase-io/" title="文件读写_ase_io"><img class="cover" src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Fcover%2F41524_2021_670_Fig2_HTML.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-11-22</div><div class="title">文件读写_ase_io</div></div></a></div><div><a href="/2024/01/20/informatique/Generative/" title="生成式神经网络总览"><img class="cover" src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fgenerative.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-20</div><div class="title">生成式神经网络总览</div></div></a></div><div><a href="/2025/02/26/informatique/deeplearning/Generative-11/" title="GAN,VAE和流模型的原理（以流模型为主）"><img class="cover" src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2F蝶1.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-02-26</div><div class="title">GAN,VAE和流模型的原理（以流模型为主）</div></div></a></div><div><a href="/2024/01/20/informatique/deeplearning/Generative_1/" title="Chapter 1 Generative Modeling"><img class="cover" src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fgenerative.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-20</div><div class="title">Chapter 1 Generative Modeling</div></div></a></div><div><a href="/2024/01/20/informatique/deeplearning/Generative_10/" title="Chapter 10 Advanced GANs 各种各样的GAN"><img class="cover" src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fgenerative.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-20</div><div class="title">Chapter 10 Advanced GANs 各种各样的GAN</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2FR-2.png" onerror="this.onerror=null;this.src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffriend_404.gif'" alt="avatar"/></div><div class="author-info__name">Raphael Hyaan</div><div class="author-info__description">何日可谓归去来</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">179</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">59</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">21</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/raphaelhyaan"><i class="fab fa-github"></i><span>Bonjour</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/raphaelhyaan" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:raphael.ma.yuhan@outlook.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">仰观宇宙之大，俯察品类之盛</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#dcgan"><span class="toc-number">1.</span> <span class="toc-text">DCGAN</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B"><span class="toc-number">2.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C"><span class="toc-number">3.</span> <span class="toc-text">生成对抗网络</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFgan"><span class="toc-number">3.1.</span> <span class="toc-text">什么是GAN？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%A6%E5%8F%B7%E5%AE%9A%E4%B9%89"><span class="toc-number">3.2.</span> <span class="toc-text">符号定义</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%89%B4%E5%88%AB%E5%99%A8"><span class="toc-number">3.2.1.</span> <span class="toc-text">鉴别器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%9F%E6%88%90%E5%99%A8"><span class="toc-number">3.2.2.</span> <span class="toc-text">生成器</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFdcgan"><span class="toc-number">3.3.</span> <span class="toc-text">什么是DCGAN？</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%BE%93%E5%85%A5"><span class="toc-number">4.</span> <span class="toc-text">输入</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE"><span class="toc-number">5.</span> <span class="toc-text">数据</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%9E%E6%96%BD"><span class="toc-number">6.</span> <span class="toc-text">实施</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9D%83%E9%87%8D%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="toc-number">6.1.</span> <span class="toc-text">权重初始化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%9F%E6%88%90%E5%99%A8-1"><span class="toc-number">6.2.</span> <span class="toc-text">生成器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%89%B4%E5%88%AB%E5%99%A8-1"><span class="toc-number">6.3.</span> <span class="toc-text">鉴别器</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%89%B4%E5%88%AB%E5%99%A8%E4%BB%A3%E7%A0%81"><span class="toc-number">6.3.1.</span> <span class="toc-text">鉴别器代码</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E4%BC%98%E5%8C%96%E5%99%A8"><span class="toc-number">6.4.</span> <span class="toc-text">损失函数和优化器</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">6.4.1.</span> <span class="toc-text">损失函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9C%9F%E5%81%87%E6%A0%87%E7%AD%BE"><span class="toc-number">6.4.2.</span> <span class="toc-text">真假标签</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E5%99%A8"><span class="toc-number">6.4.3.</span> <span class="toc-text">优化器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%99%AA%E9%9F%B3"><span class="toc-number">6.4.4.</span> <span class="toc-text">噪音</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83"><span class="toc-number">7.</span> <span class="toc-text">训练</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC1%E9%83%A8%E5%88%86---%E8%AE%AD%E7%BB%83%E9%89%B4%E5%88%AB%E5%99%A8"><span class="toc-number">7.1.</span> <span class="toc-text">第1部分 - 训练鉴别器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC2%E9%83%A8%E5%88%86---%E8%AE%AD%E7%BB%83%E7%94%9F%E6%88%90%E5%99%A8"><span class="toc-number">7.2.</span> <span class="toc-text">第2部分 - 训练生成器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC3%E9%83%A8%E5%88%86---%E7%BB%9F%E8%AE%A1%E6%8A%A5%E5%91%8A"><span class="toc-number">7.3.</span> <span class="toc-text">第3部分 - 统计报告</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BB%93%E6%9E%9C"><span class="toc-number">8.</span> <span class="toc-text">结果</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%A8%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B%E4%B8%ADd%E5%92%8Cg%E7%9A%84%E6%8D%9F%E5%A4%B1%E6%98%AF%E5%A6%82%E4%BD%95%E5%8F%98%E5%8C%96%E7%9A%84"><span class="toc-number">8.0.1.</span> <span class="toc-text">在训练过程中D和G的损失是如何变化的</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%A8%E6%AF%8F%E4%B8%AA%E5%91%A8%E6%9C%9F%E4%B8%8A%E5%8F%AF%E8%A7%86%E5%8C%96g%E5%9C%A8%E5%9B%BA%E5%AE%9A%E5%99%AA%E5%A3%B0%E6%89%B9%E6%AC%A1%E7%9A%84%E8%BE%93%E5%87%BA"><span class="toc-number">8.0.2.</span> <span class="toc-text">在每个周期上可视化G在固定噪声批次的输出</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E6%89%B9%E7%9C%9F%E5%AE%9E%E6%95%B0%E6%8D%AE%E5%92%8Cg%E7%9A%84%E4%B8%80%E6%89%B9%E5%81%87%E6%95%B0%E6%8D%AE"><span class="toc-number">8.0.3.</span> <span class="toc-text">一批真实数据和G的一批假数据</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/08/04/RH-FASTMNMF/" title="FastMNMF及改进"><img src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fpink01-s.png" onerror="this.onerror=null;this.src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="FastMNMF及改进"/></a><div class="content"><a class="title" href="/2025/08/04/RH-FASTMNMF/" title="FastMNMF及改进">FastMNMF及改进</a><time datetime="2025-08-04T14:59:12.000Z" title="发表于 2025-08-04 22:59:12">2025-08-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/08/04/RH-BF/" title="波束形成"><img src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fpink01-s.png" onerror="this.onerror=null;this.src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="波束形成"/></a><div class="content"><a class="title" href="/2025/08/04/RH-BF/" title="波束形成">波束形成</a><time datetime="2025-08-04T14:59:11.000Z" title="发表于 2025-08-04 22:59:11">2025-08-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/06/30/snake-1/" title="从北京的四种毒蛇开始"><img src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fsnake-1.png" onerror="this.onerror=null;this.src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="从北京的四种毒蛇开始"/></a><div class="content"><a class="title" href="/2025/06/30/snake-1/" title="从北京的四种毒蛇开始">从北京的四种毒蛇开始</a><time datetime="2025-06-30T14:22:54.000Z" title="发表于 2025-06-30 22:22:54">2025-06-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/06/30/RH-NMF/" title="NMF及语音分离"><img src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2FR-a.png" onerror="this.onerror=null;this.src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="NMF及语音分离"/></a><div class="content"><a class="title" href="/2025/06/30/RH-NMF/" title="NMF及语音分离">NMF及语音分离</a><time datetime="2025-06-30T13:30:25.000Z" title="发表于 2025-06-30 21:30:25">2025-06-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/06/12/RH-Kalman/" title="Kalman滤波：线性卡尔曼滤波，扩展卡尔曼滤波，无迹卡尔曼滤波"><img src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2FR-a.png" onerror="this.onerror=null;this.src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="Kalman滤波：线性卡尔曼滤波，扩展卡尔曼滤波，无迹卡尔曼滤波"/></a><div class="content"><a class="title" href="/2025/06/12/RH-Kalman/" title="Kalman滤波：线性卡尔曼滤波，扩展卡尔曼滤波，无迹卡尔曼滤波">Kalman滤波：线性卡尔曼滤波，扩展卡尔曼滤波，无迹卡尔曼滤波</a><time datetime="2025-06-12T14:50:23.000Z" title="发表于 2025-06-12 22:50:23">2025-06-12</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By Raphael Hyaan</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="framework-info"><span>备案号: </span><a href="href=&quot;https://beian.miit.gov.cn/&quot; ">京ICP备2024051904号</a><span class="footer-separator">|</span><img src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2F%E5%A4%87%E6%A1%88%E5%9B%BE%E6%A0%87.png" alt="MIT License" height="20" align="top"/><span> </span><a href="href=&quot;https://beian.mps.gov.cn/#/query/webSearch?code=11010802044068&quot; ">京公网安备11010802044068号</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>