<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Chapter 9 Transformers | Raphael's Home</title><meta name="author" content="Raphael Hyaan"><meta name="copyright" content="Raphael Hyaan"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="Chapter 9 Transformers  由于文本生成不是我的主要学习目的，本章学习不会尝试使用PyTorch复现。另一个原因是Diffusion的PyTorch版主直到本章开始学习都不能正常工作。考虑到目前对一些知识还处于一知半解的状态，且我的学习目的也并非实现Diffusion或者GPT这些网络，故暂时不会进行使用PyTorch的重现。   尽管如此，我还是在原文提供的GPT上">
<meta property="og:type" content="article">
<meta property="og:title" content="Chapter 9 Transformers">
<meta property="og:url" content="http://raphaelhyaan.cn/2024/01/20/informatique/deeplearning/Generative_9/index.html">
<meta property="og:site_name" content="Raphael&#39;s Home">
<meta property="og:description" content="Chapter 9 Transformers  由于文本生成不是我的主要学习目的，本章学习不会尝试使用PyTorch复现。另一个原因是Diffusion的PyTorch版主直到本章开始学习都不能正常工作。考虑到目前对一些知识还处于一知半解的状态，且我的学习目的也并非实现Diffusion或者GPT这些网络，故暂时不会进行使用PyTorch的重现。   尽管如此，我还是在原文提供的GPT上">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fgenerative.jpg">
<meta property="article:published_time" content="2024-01-20T08:19:15.000Z">
<meta property="article:modified_time" content="2025-02-11T00:24:25.918Z">
<meta property="article:author" content="Raphael Hyaan">
<meta property="article:tag" content="学习笔记">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="神经网络">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fgenerative.jpg"><link rel="shortcut icon" href="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Flana cat 002.png"><link rel="canonical" href="http://raphaelhyaan.cn/2024/01/20/informatique/deeplearning/Generative_9/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Chapter 9 Transformers',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-02-11 08:24:25'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/butterflyChange/css/code.css"><meta name="generator" content="Hexo 7.0.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2FR-2.png" onerror="onerror=null;src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffriend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">169</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">53</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">21</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/Reading/"><i class="fa-fw fas fa-book"></i><span> Reading</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> Gallery</span></a></li><li><a class="site-page child" href="/Video/"><i class="fa-fw fas fa-video"></i><span> Video</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FGenerative_9%2FUntitled.png')"><nav id="nav"><span id="blog-info"><a href="/" title="Raphael's Home"><span class="site-name">Raphael's Home</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/Reading/"><i class="fa-fw fas fa-book"></i><span> Reading</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> Gallery</span></a></li><li><a class="site-page child" href="/Video/"><i class="fa-fw fas fa-video"></i><span> Video</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Chapter 9 Transformers</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-01-20T08:19:15.000Z" title="发表于 2024-01-20 16:19:15">2024-01-20</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-02-11T00:24:25.918Z" title="更新于 2025-02-11 08:24:25">2025-02-11</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%94%9F%E6%88%90%E5%BC%8F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">生成式神经网络</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Chapter 9 Transformers"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="chapter-9-transformers">Chapter 9 Transformers</h1>
<blockquote>
<p>由于文本生成不是我的主要学习目的，本章学习不会尝试使用PyTorch复现。另一个原因是Diffusion的PyTorch版主直到本章开始学习都不能正常工作。考虑到目前对一些知识还处于一知半解的状态，且我的学习目的也并非实现Diffusion或者GPT这些网络，故暂时不会进行使用PyTorch的重现。</p>
</blockquote>
<blockquote>
<p>尽管如此，我还是在原文提供的GPT上进行一些“随心所欲”，或者说“完全不知道原理只是瞎改”的，修改。尽管我现在还有得到结果，但可以预料到势必会导致表现变差。</p>
</blockquote>
<blockquote>
<p>PyTorch的重现已经添加，基本架构相同，只是作用在另一个任务上。</p>
</blockquote>
<p><img
src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FGenerative_9%2FUntitled.png" /></p>
<h2 id="介绍">介绍</h2>
<ul>
<li><code>Transformer</code>神经网络是一种不需要循环或者卷积架构，依赖于注意力机制的神经网络。是目前用于文本生成的最重要的架构。</li>
<li><code>GPT</code> 全程<code>Generative Pre-Training</code>
是一种能够在大量文本数据上训练的Transformer架构。在预训练期间，模型被训练为在给定先前单词的情况下预测序列中的下一个单词。此过程称为语言建模，用于教导模型理解自然语言的结构和模式。预训练后，可以通过为
GPT 模型提供更小的、特定于任务的数据集来针对特定任务进行微调。</li>
</ul>
<h3 id="数据集">数据集</h3>
<p>原书使用了Wine Reviews
Dataset。这个数据集包含了超过13万条葡萄酒评论，其中包括了品种、产地、酒庄、价格和描述等信息。</p>
<h1 id="gpt">GPT</h1>
<blockquote>
<p>在本章中，我们将构建和了解我们自己的原始 GPT
模型的变体，使用较少的数据进行训练，但仍然利用相同的组件和基本原理</p>
</blockquote>
<h2 id="注意力机制attention">注意力机制<em>Attention</em></h2>
<blockquote>
<p>注意力机制使得 Transformer
架构独一无二，并且与语言建模的循环方法截然不同。</p>
</blockquote>
<p>与之前我们讨论过的文字生成模型相似，句子的下一个单词的选择会受到前面所有单词的影响。</p>
<aside>
<p>💡 The pink elephant tried to get into the car but it was too</p>
</aside>
<p>我们可以猜测到下一个词可能是<code>big</code>。但是作为一个人，我们是根据哪些单词猜到的下一个词是<code>big</code>
呢？<code>elephant</code>
和<code>car</code>可能是相比于<code>pink</code>等单词更为重要。换句话说，我们更多的<strong>注意</strong>到句子中的某些单词，而忽略了另外一些单词。</p>
<p>Transformer
中的<strong>注意力机制</strong>（也称为<strong>注意力头</strong><em>attention
head</em>）就是为了做到这一点而设计的。它能够决定要从输入中的何处提取信息，以便有效地提取有用的信息。</p>
<h3 id="查询queries-键keys-值values">查询<strong><em>Queries</em>,
键<em>Keys</em>, 值<em>Values</em></strong></h3>
<p>为了完成这项任务，我们为每个单词赋予一个类似于“信心”的属性。使得elephant这个单词对自己更加自信，以为下一个单词提供更多的信息；而was则对自己信心较少，以为下一个单词提供更少的信息。</p>
<p>换句话说，我们可以将注意力头理解为一种信息查询机制。下一个单词是什么这个问题被引入到一个键值对存储系统。由查询<code>Q</code>与每一个键<code>K</code>的共振<em>resonance</em>决定权重，最终的预测结果为值<code>V</code>得加权求和。如下图所示。</p>
<p><img
src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FGenerative_9%2FUntitled_1.png" /></p>
<p><strong>查询向量</strong><code>Q</code>是当前任务得一种表示。如再训练过程中，我们得任务就是简单的预测下一个单词。在上面得例子中，它是一个单词<code>too</code>，与其他单词得输入方式一致，在编码后传递给权重矩阵<span
class="math inline">\(W_Q\)</span>转换为一个<span
class="math inline">\(d_k\)</span>长度的向量<span
class="math inline">\(Q\)</span>。</p>
<p><strong>键向量</strong><code>K</code>是句子中每个单词的表示，再编码后经过权重矩阵<span
class="math inline">\(W_K\)</span>，每一个<code>K</code>都转换为一个<span
class="math inline">\(d_k\)</span>的向量<span
class="math inline">\(K\)</span>。这与查询的向量长度相同。</p>
<p>再注意力头中，使用点积计算权重；按照d_k缩放以保证方差稳定；最终经过<code>softmax</code>以保证总和为1：</p>
<p><span class="math display">\[
w_i = softmax(\frac{v_k\cdot v_q}{\sqrt{d_k}})= softmax(\frac{Q\cdot
K^T}{\sqrt{d_k}})
\]</span></p>
<p><strong>值向量</strong><code>V</code>也是句子中单词的表示，可以将它们视为每个单词的未加权贡献。也经过权重矩阵<span
class="math inline">\(W_V\)</span>转化为一个<span
class="math inline">\(d_k\)</span>的向量<span
class="math inline">\(V\)</span>。但是值向量不一定必须与键和查询具有相同的长度，只是为了简单起见，通常这样做。</p>
<p>由此，<strong>注意力<em>attention</em></strong>被定义为：</p>
<p><span class="math display">\[
\operatorname{Attention}(Q, K, V)=\operatorname{softmax}\left(\frac{Q
K^T}{\sqrt{d_k}}\right) V
\]</span></p>
<p>为了从注意力头获得最终的输出向量，注意力被求和以给出长度为 <span
class="math inline">\(d_v\)</span>
的向量。该上下文向量捕获了句子中单词的混合意见，以预测接下来的单词。</p>
<h3 id="多注意力头-multihead-attention">多注意力头 <em>Multihead
Attention</em></h3>
<blockquote>
<p>将多个注意力头的输出连接在一起，可以得到一个<em>Multihead
Attention。</em></p>
</blockquote>
<p><img
src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FGenerative_9%2FUntitled_2.png" /></p>
<p>连接的输出通过一个最终权重矩阵 <span
class="math inline">\(W_O\)</span>
传递，将向量投影到所需的输出维度。</p>
<p>在Keras中可以直接使用<code>tf.keras.layers.MultiHeadAttention</code>
来定义。而在PyTorch中，也可以使用<code>torch.nn.MultiheadAttention</code>
来定义。</p>
<p>它们的文档可以在如下两个连接中找到。</p>
<p><a
target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html">MultiheadAttention
— PyTorch 2.1 documentation</a></p>
<p><a
target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/keras/layers/MultiHeadAttention">tf.keras.layers.MultiHeadAttention
 |  TensorFlow v2.15.0.post1</a></p>
<h2 id="因果掩蔽-causal-masking">因果掩蔽 <em>Causal Masking</em></h2>
<p>之前的模型中，我们假设了输入是一个单词<code>too</code>
，我们希望注意力层能同时对输入的每一个单词进行操作，即希望GPT能并行处理一组查询向量。</p>
<p>在直接将向量一起处理成一个矩阵之前，我们需要一个额外的步骤：对查询-键点积应用掩蔽，以避免未来单词的信息泄漏。在计算注意力分数时，我们不能见到当前单词之后的单词。比如，我们希望在预测<code>it</code>之后的单词时，<code>was</code>和<code>to</code>时不可见的。</p>
<p><img
src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FGenerative_9%2FUntitled_3.png" /></p>
<p>这种掩蔽层我们曾经创建过类似的，在Keras中，我们可以将其定义为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">causal_attention_mask</span>(<span class="params">batch_size, n_dest, n_src, dtype</span>):</span><br><span class="line">		<span class="string">&#x27;&#x27;&#x27;n_dest：Q向量长度，n_src：K向量长度&#x27;&#x27;&#x27;</span></span><br><span class="line">    i = tf.<span class="built_in">range</span>(n_dest)[:, <span class="literal">None</span>]</span><br><span class="line">    j = tf.<span class="built_in">range</span>(n_src)</span><br><span class="line">    m = i &gt;= j - n_src + n_dest</span><br><span class="line">    mask = tf.cast(m, dtype)</span><br><span class="line">    mask = tf.reshape(mask, [<span class="number">1</span>, n_dest, n_src])</span><br><span class="line">    mult = tf.concat(</span><br><span class="line">        [tf.expand_dims(batch_size, -<span class="number">1</span>), tf.constant([<span class="number">1</span>, <span class="number">1</span>], dtype=tf.int32)], <span class="number">0</span></span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> tf.tile(mask, mult)</span><br></pre></td></tr></table></figure>
<p>其中， <code>m</code> 是一个布尔矩阵，如果 <code>i</code>
中的元素大于等于 <code>j</code> 中的元素减去 <code>n_src</code> 加上
<code>n_dest</code>，则对应位置为 <code>True</code>，否则为
<code>False</code>。这个矩阵的形状为
<code>(n_dest, n_src)</code>，表示在位置 <code>i</code>
是否可以关注到位置 <code>j</code>。</p>
<p>如果使用PyTorch实现这个函数，可以将尝试使用torch.triu函数。</p>
<p><a
target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.triu.html#torch.triu">torch.triu
— PyTorch 2.1 documentation</a></p>
<aside>
<p>💡 其他Transformer未必需要因果遮掩。</p>
</aside>
<p>值得注意的是，这样一个有影响力的层的可学习参数只不过是由每个注意力头的三个密集连接的权重矩阵（<span
class="math inline">\(W_Q\)</span>、<span
class="math inline">\(W_K\)</span>、<span
class="math inline">\(W_V\)</span>）和另一个用于重塑输出的权重矩阵（<span
class="math inline">\(W_O\)</span>）组成。</p>
<h2 id="transformer-block">Transformer Block</h2>
<blockquote>
<p>Transformer 块是 Transformer
中的单个组件，它应用一些跳跃连接、前馈（密集）层和围绕多头注意力层的归一化。</p>
</blockquote>
<p><img
src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FGenerative_9%2FUntitled_4.png" /></p>
<h3 id="层归一化-layer-normalization">层归一化 <em>layer
normalization</em></h3>
<blockquote>
<p>层归一化对批次中每个序列的同一位置进行<strong>跨通道的</strong>归一化。</p>
</blockquote>
<p><img
src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FGenerative_9%2FUntitled_5.png" /></p>
<p>在Keras中可以通过<code>tf.keras.layers.LayerNormalization</code>
实现，而在PyTorch中可以通过<code>torch.nn.LayerNorm</code> 实现。</p>
<p><a
target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html">LayerNorm
— PyTorch 2.1 documentation</a></p>
<p><a
target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/keras/layers/LayerNormalization?hl=en">tf.keras.layers.LayerNormalization
 |  TensorFlow v2.15.0.post1</a></p>
<h3 id="构建transformer-block">构建Transformer Block</h3>
<p>在Keras中，如下定义Transformer Block块:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TransformerBlock</span>(layers.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_heads, key_dim, embed_dim, ff_dim, dropout_rate=<span class="number">0.1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(TransformerBlock, self).__init__()</span><br><span class="line">        self.num_heads = num_heads</span><br><span class="line">        self.key_dim = key_dim</span><br><span class="line">        self.embed_dim = embed_dim</span><br><span class="line">        self.ff_dim = ff_dim</span><br><span class="line">        self.dropout_rate = dropout_rate</span><br><span class="line">        self.attn = layers.MultiHeadAttention(num_heads, key_dim, output_shape=embed_dim)</span><br><span class="line">        self.dropout_1 = layers.Dropout(self.dropout_rate)</span><br><span class="line">        self.ln_1 = layers.LayerNormalization(epsilon=<span class="number">1e-6</span>)</span><br><span class="line">        self.ffn_1 = layers.Dense(self.ff_dim, activation=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">        self.ffn_2 = layers.Dense(self.embed_dim)</span><br><span class="line">        self.dropout_2 = layers.Dropout(self.dropout_rate)</span><br><span class="line">        self.ln_2 = layers.LayerNormalization(epsilon=<span class="number">1e-6</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, inputs</span>):</span><br><span class="line">        input_shape = tf.shape(inputs)</span><br><span class="line">        batch_size = input_shape[<span class="number">0</span>]</span><br><span class="line">        seq_len = input_shape[<span class="number">1</span>]</span><br><span class="line">        causal_mask = causal_attention_mask(</span><br><span class="line">            batch_size, seq_len, seq_len, tf.<span class="built_in">bool</span></span><br><span class="line">        )</span><br><span class="line">        attention_output, attention_scores = self.attn(</span><br><span class="line">            inputs,</span><br><span class="line">            inputs,</span><br><span class="line">            attention_mask=causal_mask,</span><br><span class="line">            return_attention_scores=<span class="literal">True</span>,</span><br><span class="line">        )</span><br><span class="line">        attention_output = self.dropout_1(attention_output)</span><br><span class="line">        out1 = self.ln_1(inputs + attention_output)</span><br><span class="line">        ffn_1 = self.ffn_1(out1)</span><br><span class="line">        ffn_2 = self.ffn_2(ffn_1)</span><br><span class="line">        ffn_output = self.dropout_2(ffn_2)</span><br><span class="line">        <span class="keyword">return</span> (self.ln_2(out1 + ffn_output), attention_scores)</span><br></pre></td></tr></table></figure>
<h2 id="位置编码-positional-encoding">位置编码 <em>Positional
Encoding</em></h2>
<p>现在的GPT模型中没有任何机制能够区分输入的顺序。因此注意力层不能分辨以下两句话。</p>
<ul>
<li><code>The dog looked at the boy and ... (barked?)</code></li>
<li><code>The boy looked at the dog and ... (smiled?)</code></li>
</ul>
<p>因此，我们在创建Transfomer块时使用位置编码技术。如此，我们不仅使用token
embedding对字符进行编码，还要使用position
embedding对位置进行编码。我们同样使用一个embedding层实现，并于token
embedding结合构成token–position encoding。</p>
<p><img
src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FGenerative_9%2FUntitled_6.png" /></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TokenAndPositionEmbedding</span>(layers.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, max_len, vocab_size, embed_dim</span>):</span><br><span class="line">        <span class="built_in">super</span>(TokenAndPositionEmbedding, self).__init__()</span><br><span class="line">        self.max_len = max_len</span><br><span class="line">        self.vocab_size = vocab_size</span><br><span class="line">        self.embed_dim = embed_dim</span><br><span class="line">        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)</span><br><span class="line">        self.pos_emb = layers.Embedding(input_dim=max_len, output_dim=embed_dim)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, x</span>):</span><br><span class="line">        maxlen = tf.shape(x)[-<span class="number">1</span>]</span><br><span class="line">        positions = tf.<span class="built_in">range</span>(start=<span class="number">0</span>, limit=maxlen, delta=<span class="number">1</span>)</span><br><span class="line">        positions = self.pos_emb(positions)</span><br><span class="line">        x = self.token_emb(x)</span><br><span class="line">        <span class="keyword">return</span> **x + positions**</span><br></pre></td></tr></table></figure>
<h2 id="模型训练">模型训练</h2>
<h3 id="构建网络">构建网络</h3>
<blockquote>
<p>我们构建一个仅包括一个transformer块的网络</p>
</blockquote>
<p><img
src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FGenerative_9%2FUntitled_7.png" /></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">inputs = layers.Input(shape=(<span class="literal">None</span>,), dtype=tf.int32)</span><br><span class="line">x = TokenAndPositionEmbedding(MAX_LEN, VOCAB_SIZE, EMBEDDING_DIM)(inputs)</span><br><span class="line">x, attention_scores = TransformerBlock(N_HEADS, KEY_DIM, EMBEDDING_DIM, FEED_FORWARD_DIM)(x)</span><br><span class="line">outputs = layers.Dense(VOCAB_SIZE, activation=<span class="string">&quot;softmax&quot;</span>)(x)</span><br><span class="line">gpt = models.Model(inputs=inputs, outputs=[outputs, attention_scores])</span><br><span class="line">gpt.<span class="built_in">compile</span>(<span class="string">&quot;adam&quot;</span>, loss=[losses.SparseCategoricalCrossentropy(), <span class="literal">None</span>])</span><br></pre></td></tr></table></figure>
<p>使用adam优化器和交叉熵损失（在torch中被定义为<code>torch.nn.CrossEntropyLoss</code>
）开始训练。</p>
<h2 id="结果分析">结果分析</h2>
<p>总体来看，结果相比于之前的使用lstm实现的效果好许多。以下是输入为：<code>水 调 歌 头 : 明 月 几 时 有 ，</code>
时生成的词的下半阙和下半阙的第一句。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">水 调 歌 头 </span><br><span class="line">明 月 几 时 有 ， 图 画 上 高 楼 。 </span><br><span class="line">烟 鬟 **雾** 鬓 ， 玉 臂 金 印 印 金 钩 。 </span><br><span class="line">把 酒 频 倾 潋 滟 ， 更 祝 西 风 十 里 ， 不 似 醉 时 休 。 </span><br><span class="line">莫 怪 老 人 醉 ， 无 奈 有 何 忧 。 </span><br><span class="line">青 箬 绿 ， 红 鳞 远 ， 绿 波 流 。</span><br><span class="line">坐 中 日 月 ， 未 **应** 不 见 两 相 留 。</span><br><span class="line">却 是 明 年 何 事 ， 却 恐 青 云 飞 去 ， 空 恁 地 偏 羞 。</span><br><span class="line">寄 语 故 园 客 ， 一 笑 问 君 留 。</span><br></pre></td></tr></table></figure>
<p>它很不错的完成了格律和局部的语义连贯，很值得赞叹。这一部分唯一的不正确的格律为<code>雾</code>和<code>应</code>两字。</p>
<p>以下是部分有意思的细节。</p>
<p><strong>对句号位置的把控</strong>
模型似乎可以很好的把控句号的位置，使得尽管有时逗号的位置不对，但每一句话的长度正确率较高。这可能部分词的变体导致逗号位置不固定引入的问题。</p>
<p><img
src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FGenerative_9%2FUntitled_8.png" /></p>
<p><img
src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FGenerative_9%2FUntitled_9.png" /></p>
<p><strong>对韵脚的把控</strong>
模型似乎能正确的根据韵脚填词，比如在填<code>钩</code>和<code>休</code>时，<code>楼</code>的权重都很大。</p>
<p><img
src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FGenerative_9%2FUntitled_10.png" /></p>
<p><img
src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FGenerative_9%2FUntitled_11.png" /></p>
<p><img
src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FGenerative_9%2FUntitled_12.png" /></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://raphaelhyaan.cn">Raphael Hyaan</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://raphaelhyaan.cn/2024/01/20/informatique/deeplearning/Generative_9/">http://raphaelhyaan.cn/2024/01/20/informatique/deeplearning/Generative_9/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://raphaelhyaan.cn" target="_blank">Raphael's Home</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><a class="post-meta__tags" href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">神经网络</a></div><div class="post_share"></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/01/20/informatique/deeplearning/Generative_10/" title="Chapter 10 Advanced GANs 各种各样的GAN"><img class="cover" src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fgenerative.jpg" onerror="onerror=null;src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Chapter 10 Advanced GANs 各种各样的GAN</div></div></a></div><div class="next-post pull-right"><a href="/2024/01/20/informatique/deeplearning/Generative_8/" title="Chapter 8 Diffusion Models 扩散模型"><img class="cover" src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fgenerative.jpg" onerror="onerror=null;src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Chapter 8 Diffusion Models 扩散模型</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2025/02/26/informatique/deeplearning/Generative-11/" title="GAN,VAE和流模型的原理（以流模型为主）"><img class="cover" src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2F蝶1.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-02-26</div><div class="title">GAN,VAE和流模型的原理（以流模型为主）</div></div></a></div><div><a href="/2024/01/20/informatique/deeplearning/Generative_10/" title="Chapter 10 Advanced GANs 各种各样的GAN"><img class="cover" src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fgenerative.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-20</div><div class="title">Chapter 10 Advanced GANs 各种各样的GAN</div></div></a></div><div><a href="/2024/01/20/informatique/deeplearning/Generative_1/" title="Chapter 1 Generative Modeling"><img class="cover" src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fgenerative.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-20</div><div class="title">Chapter 1 Generative Modeling</div></div></a></div><div><a href="/2024/01/20/informatique/deeplearning/Generative_3/" title="Chapter 3 Variational Autoencoders 自动变分编码器"><img class="cover" src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fgenerative.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-20</div><div class="title">Chapter 3 Variational Autoencoders 自动变分编码器</div></div></a></div><div><a href="/2024/01/20/informatique/deeplearning/Generative_2/" title="Chapter 2 Deep Learning"><img class="cover" src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fgenerative.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-20</div><div class="title">Chapter 2 Deep Learning</div></div></a></div><div><a href="/2024/01/20/informatique/deeplearning/Generative_5/" title="Chapter 5 Autoregressive Models 自回归模型"><img class="cover" src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fgenerative.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-20</div><div class="title">Chapter 5 Autoregressive Models 自回归模型</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2FR-2.png" onerror="this.onerror=null;this.src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffriend_404.gif'" alt="avatar"/></div><div class="author-info__name">Raphael Hyaan</div><div class="author-info__description">何日可谓归去来</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">169</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">53</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">21</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/raphaelhyaan"><i class="fab fa-github"></i><span>Bonjour</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/raphaelhyaan" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:raphael.ma.yuhan@outlook.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">仰观宇宙之大，俯察品类之盛</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#chapter-9-transformers"><span class="toc-number">1.</span> <span class="toc-text">Chapter 9 Transformers</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.1.</span> <span class="toc-text">介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.1.1.</span> <span class="toc-text">数据集</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#gpt"><span class="toc-number">2.</span> <span class="toc-text">GPT</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6attention"><span class="toc-number">2.1.</span> <span class="toc-text">注意力机制Attention</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9F%A5%E8%AF%A2queries-%E9%94%AEkeys-%E5%80%BCvalues"><span class="toc-number">2.1.1.</span> <span class="toc-text">查询Queries,
键Keys, 值Values</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%A4%B4-multihead-attention"><span class="toc-number">2.1.2.</span> <span class="toc-text">多注意力头 Multihead
Attention</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%A0%E6%9E%9C%E6%8E%A9%E8%94%BD-causal-masking"><span class="toc-number">2.2.</span> <span class="toc-text">因果掩蔽 Causal Masking</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#transformer-block"><span class="toc-number">2.3.</span> <span class="toc-text">Transformer Block</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B1%82%E5%BD%92%E4%B8%80%E5%8C%96-layer-normalization"><span class="toc-number">2.3.1.</span> <span class="toc-text">层归一化 layer
normalization</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9E%84%E5%BB%BAtransformer-block"><span class="toc-number">2.3.2.</span> <span class="toc-text">构建Transformer Block</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81-positional-encoding"><span class="toc-number">2.4.</span> <span class="toc-text">位置编码 Positional
Encoding</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83"><span class="toc-number">2.5.</span> <span class="toc-text">模型训练</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9E%84%E5%BB%BA%E7%BD%91%E7%BB%9C"><span class="toc-number">2.5.1.</span> <span class="toc-text">构建网络</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90"><span class="toc-number">2.6.</span> <span class="toc-text">结果分析</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/04/24/zj-gccgdp/" title="关于g++/gdp的安装和vscode配置"><img src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2F蔀易染.png" onerror="this.onerror=null;this.src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="关于g++/gdp的安装和vscode配置"/></a><div class="content"><a class="title" href="/2025/04/24/zj-gccgdp/" title="关于g++/gdp的安装和vscode配置">关于g++/gdp的安装和vscode配置</a><time datetime="2025-04-24T11:38:12.000Z" title="发表于 2025-04-24 19:38:12">2025-04-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/04/21/eles-1/" title="Amplification 放大器"><img src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2F入云.png" onerror="this.onerror=null;this.src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="Amplification 放大器"/></a><div class="content"><a class="title" href="/2025/04/21/eles-1/" title="Amplification 放大器">Amplification 放大器</a><time datetime="2025-04-21T01:05:01.000Z" title="发表于 2025-04-21 09:05:01">2025-04-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/02/26/informatique/deeplearning/Generative-11/" title="GAN,VAE和流模型的原理（以流模型为主）"><img src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2F蝶1.png" onerror="this.onerror=null;this.src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="GAN,VAE和流模型的原理（以流模型为主）"/></a><div class="content"><a class="title" href="/2025/02/26/informatique/deeplearning/Generative-11/" title="GAN,VAE和流模型的原理（以流模型为主）">GAN,VAE和流模型的原理（以流模型为主）</a><time datetime="2025-02-26T08:30:58.000Z" title="发表于 2025-02-26 16:30:58">2025-02-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/02/11/informatique/java/java-5/" title="J05 同步"><img src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fanon cat 006.png" onerror="this.onerror=null;this.src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="J05 同步"/></a><div class="content"><a class="title" href="/2025/02/11/informatique/java/java-5/" title="J05 同步">J05 同步</a><time datetime="2025-02-11T00:23:20.000Z" title="发表于 2025-02-11 08:23:20">2025-02-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/02/11/informatique/java/java-4/" title="J04 测试"><img src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fanon cat 006.png" onerror="this.onerror=null;this.src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="J04 测试"/></a><div class="content"><a class="title" href="/2025/02/11/informatique/java/java-4/" title="J04 测试">J04 测试</a><time datetime="2025-02-11T00:23:19.000Z" title="发表于 2025-02-11 08:23:19">2025-02-11</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By Raphael Hyaan</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="framework-info"><span>备案号: </span><a href="href=&quot;https://beian.miit.gov.cn/&quot; ">京ICP备2024051904号</a><span class="footer-separator">|</span><img src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2F%E5%A4%87%E6%A1%88%E5%9B%BE%E6%A0%87.png" alt="MIT License" height="20" align="top"/><span> </span><a href="href=&quot;https://beian.mps.gov.cn/#/query/webSearch?code=11010802044068&quot; ">京公网安备11010802044068号</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>