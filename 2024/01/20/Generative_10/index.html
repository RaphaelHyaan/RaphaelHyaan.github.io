<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Chapter 10 Advanced GANs 各种各样的GAN | Raphael's Home</title><meta name="author" content="Raphael Hyaan"><meta name="copyright" content="Raphael Hyaan"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="Chapter 10 Advanced GANs 各种各样的GAN  在本次学习的最后，回归最初学习的目的，来尝试了解各种各样的GAN网络。我可能会尝试实现其中的一些模型。    三个的建立在早期论文思想上的重要模型ProGAN → StyleGAN → StyleGAN2  了解ProGAN模型。 理解ProGAN如何被改造以构建StyleGAN 探索StyleGAN如何被">
<meta property="og:type" content="article">
<meta property="og:title" content="Chapter 10 Advanced GANs 各种各样的GAN">
<meta property="og:url" content="http://raphaelhyaan.cn/2024/01/20/Generative_10/index.html">
<meta property="og:site_name" content="Raphael&#39;s Home">
<meta property="og:description" content="Chapter 10 Advanced GANs 各种各样的GAN  在本次学习的最后，回归最初学习的目的，来尝试了解各种各样的GAN网络。我可能会尝试实现其中的一些模型。    三个的建立在早期论文思想上的重要模型ProGAN → StyleGAN → StyleGAN2  了解ProGAN模型。 理解ProGAN如何被改造以构建StyleGAN 探索StyleGAN如何被">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fgenerative.jpg">
<meta property="article:published_time" content="2024-01-20T09:19:06.000Z">
<meta property="article:modified_time" content="2024-01-20T08:23:14.449Z">
<meta property="article:author" content="Raphael Hyaan">
<meta property="article:tag" content="学习笔记">
<meta property="article:tag" content="深度学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fgenerative.jpg"><link rel="shortcut icon" href="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Freading1.png"><link rel="canonical" href="http://raphaelhyaan.cn/2024/01/20/Generative_10/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Chapter 10 Advanced GANs 各种各样的GAN',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-01-20 16:23:14'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/butterflyChange/css/code.css"><meta name="generator" content="Hexo 7.0.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Fe747243b42e6168d02fdf8bccbbd4ea.jpg" onerror="onerror=null;src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffriend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">99</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">27</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/Reading/"><i class="fa-fw fas fa-book"></i><span> Reading</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> Gallery</span></a></li><li><a class="site-page child" href="/Video/"><i class="fa-fw fas fa-video"></i><span> Video</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FGenerative_10%2FUntitled.png')"><nav id="nav"><span id="blog-info"><a href="/" title="Raphael's Home"><span class="site-name">Raphael's Home</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/Reading/"><i class="fa-fw fas fa-book"></i><span> Reading</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> Gallery</span></a></li><li><a class="site-page child" href="/Video/"><i class="fa-fw fas fa-video"></i><span> Video</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Chapter 10 Advanced GANs 各种各样的GAN</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-01-20T09:19:06.000Z" title="发表于 2024-01-20 17:19:06">2024-01-20</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-01-20T08:23:14.449Z" title="更新于 2024-01-20 16:23:14">2024-01-20</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%94%9F%E6%88%90%E5%BC%8F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">学习笔记-生成式神经网络</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Chapter 10 Advanced GANs 各种各样的GAN"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="chapter-10-advanced-gans-各种各样的gan">Chapter 10 Advanced GANs
各种各样的GAN</h1>
<blockquote>
<p>在本次学习的最后，回归最初学习的目的，来尝试了解各种各样的GAN网络。我可能会尝试实现其中的一些模型。</p>
</blockquote>
<p><img
src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FGenerative_10%2FUntitled.png" /></p>
<ul>
<li>三个的建立在早期论文思想上的重要模型<code>ProGAN → StyleGAN → StyleGAN2</code>
<ul>
<li>了解<code>ProGAN</code>模型。</li>
<li>理解<code>ProGAN</code>如何被改造以构建<code>StyleGAN</code></li>
<li>探索<code>StyleGAN</code>如何被调整以创建<code>StyleGAN2</code></li>
<li>了解这些模型的关键贡献，包括渐进式训练、自适应实例归一化、权重调制和解调以及路径长度正则化。’</li>
</ul></li>
<li>两个引入了注意力机制的模型<code>SAGAN → BigGAN</code>
<ul>
<li>了解<code>Self-Attention GAN (SAGAN)</code>的架构，该架构将注意力机制纳入<code>GAN</code>框架。</li>
<li>了解<code>BigGAN</code>如何扩展<code>SAGAN</code>论文中的想法以产生高质量的图像。</li>
</ul></li>
<li>两个融合了VAE，Transformers和GAN思想的模型<code>VQ-GAN → ViT VQ-GAN</code>
<ul>
<li>了解<code>VQ-GAN</code>如何使用码本将图像编码为可以使用<code>Transformer</code>建模的离散序列的token。</li>
<li>了解<code>ViT VQ-GAN</code>如何调整<code>VQ-GAN</code>架构以在编码器和解码器中使用<code>Transformers</code>而不是卷积层。</li>
</ul></li>
</ul>
<h1 id="progan">ProGAN</h1>
<blockquote>
<p>ProGAN旨在提高GAN的训练速度和稳定性。它引入了渐进训练机制。</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.paperspace.com/progan/">ProGAN: Progressive
Growing Generative Adversarial Networks</a></p>
<h2 id="progressive">Progressive</h2>
<p>渐进训练主张首先训练一个轻量级的GAN来使出准确的低分辨率图像，然后逐步提高分辨率。</p>
<p><img
src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FGenerative_10%2FUntitled_1.png" /></p>
<h2 id="网络结构">网络结构</h2>
<p>首先我们构建一个能够生成<span
class="math inline">\(4\times4\times3\)</span>的图像的模型。其中蓝色块表示特征图和RGB的相互转变的卷积层。而且在这一步中，上采样并不是通过转置卷积实现，而是使用padding将一个<span
class="math inline">\(1\times1\times512\)</span>的图像直接补充到<span
class="math inline">\(4\times4\times512\)</span>，再经过一个卷积层来实现。</p>
<p><img
src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FGenerative_10%2FUntitled_2.png" /></p>
<p>接下来，我们关注现在训练的模型如何应用于更高分辨率的图像。</p>
<p><img
src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FGenerative_10%2FUntitled_3.png" /></p>
<p><img
src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FGenerative_10%2FUntitled_4.png" /></p>
<p>生成器和判别器的训练方式相似。</p>
<ul>
<li>对于生成器，图像经过与之前步骤相同的处理转化为<span
class="math inline">\(4\times4\times512\)</span>的特征，然后经过上采样得到<span
class="math inline">\(8\times8\times512\)</span>的新特征。特征会分别经过<code>旧toRGB块</code>和<code>新toRGB块</code>生成新图像，并通过权重<span
class="math inline">\(\alpha\)</span>加权得到最终的图像。再训练过程中，<span
class="math inline">\(\alpha\)</span>逐渐增大，直到完全不经过<code>旧toRGB块</code>。</li>
<li>对于判别器，图像同时被下采样后经过<code>旧fromRGB块</code>和经过<code>新fromRGB块</code>后进行处理，两条路径的结果经过<span
class="math inline">\(\alpha\)</span>的权重加权平均得到一个<span
class="math inline">\(4\times4\times512\)</span>的向量，并经过相同的处理得到预测结果。<span
class="math inline">\(\alpha\)</span>不断增大，直到完全不经过<code>旧fromRGB块</code>
。</li>
</ul>
<p>再提升到<span
class="math inline">\(8\times8\)</span>的分辨率后，我们在原本的生成器上增加一个上采样层，一个卷积层和一个toRGB块。在原本的判别器上增加了一个fromRGB块，一个卷积层和一个下采样。在训练过程中，每次我们提升分辨率都会增加这些层。我们的训练过程可以表示为：</p>
<p><img
src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FGenerative_10%2FUntitled_5.png" /></p>
<p><img
src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FGenerative_10%2FUntitled_6.png" /></p>
<p>注意所有的层都是可以训练的，没有任何层被锁死。</p>
<h2 id="一些其他细节">一些其他细节</h2>
<h3 id="小批次标准偏差-minibatch-standard-deviation">小批次标准偏差
<em>Minibatch standard deviation</em></h3>
<p>小批次标准偏差层是鉴别器中的一个额外层，它附加特征值的标准偏差，在所有像素和微批次上进行平均，作为附加（恒定）特征。</p>
<p>这有利于生成器在输出中创造更多的多样性。</p>
<h3 id="均衡学习率-equalized-learning-rates">均衡学习率 <em>Equalized
learning rates</em></h3>
<p>ProGAN中的所有全连接层和卷积层都使用均衡的学习率。</p>
<p>通常，神经网络中的权重是使用He初始化等方法初始化的，He初始化是一种高斯分布，其中标准偏差被缩放为与层输入数量的平方根成反比。这样，具有更多输入数量的层将被初始化为具有与零的较小偏差的权重，这通常提高了训练过程的稳定性。</p>
<p>ProGAN的研究发现在使用Adam或RMSProp这些优化器时，这回造成问题。会导致时间花费更长，且两个模型的训练速度不平衡。</p>
<p>通过均衡的学习率，我们可以相应地缩放每一层的权重。该公式类似于He初始化。但是，均衡学习率并没有将其用作单个初始化器，而是在每个前向传递中使用它。</p>
<h3 id="逐像素归一化-pixelwise-normalization">逐像素归一化 <em>Pixelwise
normalization</em></h3>
<p>最后，在ProGAN中，生成器中使用逐像素归一化，而不是批量归一化。逐像素归一化层没有可训练的权重。</p>
<h1 id="stylegan"><strong>StyleGAN</strong></h1>
<p>在训练GANs时，很难在潜在空间中分离出与高级属性相对应的向量，它们经常纠缠在一起，比如我们生成的图像面部出现更多雀斑，或者背景的颜色出现在面部等等。StyleGAN旨在完全控制图像的风格，即准确的分离潜在空间的特征。</p>
<h2 id="结构">结构</h2>
<p>StyleGAN通过在不同的位置将<strong>样式向量<em>style
vector</em></strong>显式地注入网络来实现这一点，下图是StyleGAN的整体结构。</p>
<p><img
src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FGenerative_10%2FUntitled_7.png" /></p>
<h2 id="mapping-network">Mapping Network</h2>
<p><code>Mapping Network</code>是一系列向前传播的神经网络，将噪音输入映射到不同的潜在空间<span
class="math inline">\(\mathcal{W}\)</span>，为输入向量被分解提供可能。这样做使得选择图像风格的过程（<code>Mapping Network</code>）和生成给定风格的图像的过程（<code>Synthesis Network</code>）分离。</p>
<h2 id="synthesis-network">Synthesis Network</h2>
<p><code>Synthesis Network</code>根据<code>Mapping Network</code>提供的风格，生成具有这些风格的图像。风格向量<span
class="math inline">\(\mathbf{w}\)</span>在不同的点被注入到合成网络中。向量通过<strong>不同的全连接层</strong><span
class="math inline">\(\mathbf{A}_i\)</span>，给出两个向量：缩放向量<span
class="math inline">\(y_{s,i}\)</span>和平移向量<span
class="math inline">\(y_{b,i}\)</span>。这些向量告诉网络如何调整特征图。这些调整通过<code>AdalN</code>层实现。</p>
<h3 id="adaln层">AdalN层</h3>
<p><code>AdalN</code>层<em>adaptive instance normalization
layers</em>使用风格的两个向量调整特征图x_i的均值和方差。这一层不改变特征图尺寸。</p>
<p><span class="math display">\[
\operatorname{AdaIN}\left(\mathbf{x}_i, \mathbf{y}\right)=\mathbf{y}_{s,
i}
\frac{\mathbf{x}_i-\mu\left(\mathbf{x}_i\right)}{\sigma\left(\mathbf{x}_i\right)}+\mathbf{y}_{b,
i}
\]</span></p>
<p>AdaIN层保证在图像被加工的每一步都能接收到完整的风格信息，从而避免在传递过程中风格信息的丢失。这可以使得潜在向量中的特征更容易分离。</p>
<h3 id="风格混合-style-mixing">风格混合 <em>Style Mixing</em></h3>
<p>作者使用了一种称为样式混合的技巧来确保生成器在训练期间不能利用相邻样式之间的相关性。在实践中，并非只采样了一个潜在向量<span
class="math inline">\(\mathbf{z}\)</span>，而是同时采样了两个潜在向量<span
class="math inline">\(\left(\mathbf{z}_1,
\mathbf{z}_2\right)\)</span>，并得到了两个风格<span
class="math inline">\(\left(w_1,
w_2\right)\)</span>向量。在每一层，这两个向量被随机选择，从而打破向量之间任何可能的相关性。</p>
<h3 id="随机变化-stochastic-variation">随机变化 <em>Stochastic
variation</em></h3>
<p>生成器在每次卷积之后都会增加噪音，以充分考虑局部的细节。</p>
<h1 id="stylegan2"><strong>StyleGAN2</strong></h1>
<p>这一系列重要的 GAN 论文中的最后一个贡献是 StyleGAN2。它进一步建立在
StyleGAN
架构的基础上，并进行了一些关键的更改，以提高生成输出的质量。</p>
<h2
id="权重调制与解调-weight-modulation-and-demodulation">权重调制与解调
<em>Weight Modulation and Demodulation</em></h2>
<p>StyleGAN2移除了AdalN层并应用权重调制和解调来提升图片质量。</p>
<p><img
src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FGenerative_10%2FUntitled_8.png" /></p>
<p><code>StyleGAN</code>中的
<code>AdaIN</code>层只是一个归一化加风格调制（缩放和偏差）。
<code>StyleGAN2</code>的想法是在运行时将风格调制和归一化（解调）直接应用于卷积层的权重，而不是卷积层的输出。</p>
<p>在 <code>StyleGAN2</code>中，每个密集层<span
class="math inline">\(\mathbf A\)</span>输出单个风格向量 <span
class="math inline">\(s_i\)</span> ，其中 <span
class="math inline">\(i\)</span>
索引相应卷积层中输入通道的数量。然后将风格向量作用于权重：<span
class="math inline">\(w_{i, j, k}^{\prime}=s_i \cdot w_{i, j,
k}\)</span>，即调制步骤。</p>
<p>接下来对调制的权重应用归一化，称为解调：<span
class="math inline">\(w_{i, j, k}^{\prime \prime}=\frac{w_{i, j,
k}^{\prime}}{\sqrt{\sum_{i, k} w_{i, j,
k}^{\prime}+\varepsilon}}\)</span></p>
<h2 id="路径长度正则化-path-length-regularization">路径长度正则化
<em>Path Length Regularization</em></h2>
<p>路径长度正则化在损失函数中引入了一个额外的惩罚项，我们希望潜在空间尽可能的平滑和均匀，以便任何方向上的潜在空间中固定大小的补偿都会导致图像中固定的变化。</p>
<p>为了实现这个目标，StyleGAN2旨在最小化以下函数：</p>
<p><span class="math display">\[
\mathbb{E}_{w, y}\left(\left\|\mathbf{J}_w^{\top} y\right\|_2-a\right)^2
\]</span></p>
<p>其中<span
class="math inline">\(w\)</span>是<code>mapping network</code>创建的风格向量集合，<span
class="math inline">\(y\)</span>是由<span
class="math inline">\(\mathscr{N}(0,
\mathbf{I})\)</span>绘制的受到噪音干扰的图像集合。<span
class="math inline">\(J_w\)</span>是生成器相对于风格向量的雅可比矩阵。</p>
<p><span class="math inline">\(\left\|\mathbf{J}_w^{\top}
y\right\|_2\)</span>测量图像变化的大小，如上述，我们希望这个变化趋近于一个常数<span
class="math inline">\(a\)</span></p>
<p>此外，为了提高效率，损失函数中的正则化项仅每 16
个小批量应用一次。这种技术称为<strong>惰性正则化</strong> <em>lazy
regularization</em>，不会导致性能明显下降。</p>
<h2 id="非渐进式生长-no-progressive-growing">非渐进式生长 <em>No
Progressive Growing</em></h2>
<p>StyleGAN2
没有采用通常的渐进式训练机制，而是利用生成器中的跳跃连接和鉴别器中的剩余连接来将整个网络训练为一个整体。</p>
<p><img
src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FGenerative_10%2FUntitled_9.png" /></p>
<p>作者表明，使用这种架构确实保留了这个属性。每个网络都受益于在训练的早期阶段细化较低分辨率层中的卷积权重，而用于将输出传递到较高分辨率层的跳跃连接和残差连接几乎不受影响。随着训练的进行，更高分辨率的层开始占据主导地位。</p>
<p><a
target="_blank" rel="noopener" href="https://github.com/autonomousvision/stylegan-xl">https://github.com/autonomousvision/stylegan-xl</a></p>
<h1 id="self-attention-gan-sagan"><strong>Self-Attention GAN
(SAGAN)</strong></h1>
<p>SAGAN展示了Transformer机制引入GAN模型可能性。</p>
<p><a
target="_blank" rel="noopener" href="https://github.com/brain-research/self-attention-gan">https://github.com/brain-research/self-attention-gan</a></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1805.08318">Self-Attention Generative
Adversarial Networks</a></p>
<p><img
src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FGenerative_10%2FUntitled_10.png" /></p>
<p>不包含注意力机制的基于 GAN
的模型的问题在于，卷积特征图只能在局部处理信息。将像素信息从图像的一侧连接到另一侧需要多个卷积层。在整个过程中，为了捕获更高级别的特征，精确的位置信息被减少，这使得模型学习远程连接像素之间的远程依赖关系的计算效率低下。</p>
<p><img
src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FGenerative_10%2FUntitled_11.png" /></p>
<p>比如，红色点的相关信息都在鸟的身上，GAN比较容易处理。而绿色点的相关信息需要跨过鸟到另一侧。这并不容易被GAN学习到。而三色点所在的尾部本身细长，也是GAN不能很容易学习的特征。</p>
<h1 id="biggan"><strong>BigGAN</strong></h1>
<p>BigGAN继承并扩展了SAGAN的思想。</p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1809.11096">Large Scale GAN Training
for High Fidelity Natural Image Synthesis</a></p>
<p><a
target="_blank" rel="noopener" href="https://www.tensorflow.org/hub/tutorials/biggan_generation_with_tf_hub?hl=zh-cn">使用
BigGAN 生成图像  |  TensorFlow Hub</a></p>
<h1 id="vq-gan">VQ-GAN</h1>
<p>GAN 的另一种重要类型是<strong>矢量量化</strong><em>Vector
Quantize</em> GAN（VQ-GAN)。这项功罪最初由VQ-VAE引入。</p>
<p>通过离散潜在空间，即学习的向量列表（密码本），每个向量都与相应的索引相关联。VQ-VAE
中编码器的工作是将输入图像折叠为较小的向量网格，然后将其与码本进行比较。然后将与每个网格方向量最接近的码本向量（通过欧几里得距离）向前传送以由解码器进行解码。</p>
<p><img
src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FGenerative_10%2FUntitled_12.png" /></p>
<p>码本可以被认为是由编码器和解码器共享的一组学习的离散概念，以便描述给定图像的内容。</p>
<p>这种架构提出了一个问题：我们如何对新颖的代码网格进行采样以传递给解码器以生成新图像？显然，为每个网格方块以相同的概率选择编码是行不通的。作者使用了另一个模型，即自回归
PixelCNN，来预测网格中的下一个代码向量，给定之前的代码向量。</p>
<p><img
src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FGenerative_10%2FUntitled_13.png" /></p>
<ul>
<li>作者添加了一个 GAN 判别器，试图区分 VAE
解码器的输出和真实图像，并在损失函数中附带对抗项。这一添加提高了整体图像质量。</li>
<li>在此之后，GAN
判别器被修改为预测图像的一部分是真还是假，而不是一次性预测整个图像。由此，损失函数可以根据图像的风格而不是内容来衡量判别器区分图像的能力。</li>
<li>然后，VQ-GAN 没有使用比较输入图像像素与 VAE
解码器的输出像素的MSE损失函数，而是使用感知损失项<em>Perceptual
loss</em>来计算编码器中间层特征图之间以及解码器的相应层的差异。</li>
<li>最后，使用 Transformer 代替 PixelCNN
作为模型的自回归部分，经过训练来生成编码序列。</li>
</ul>
<h1 id="vit-vq-gan"><strong>ViT VQ-GAN</strong></h1>
<p>在2021年，Yu等人对 VQ-GAN 进行了最后的扩展，作者展示了如何用
Transformer 替换 VQ-GAN 的卷积编码器和解码器。</p>
<p><a
target="_blank" rel="noopener" href="https://blog.research.google/2022/05/vector-quantized-image-modeling-with.html">Vector-Quantized
Image Modeling with Improved VQGAN</a></p>
<p>作者使用视觉变换器（ViT）将图像划分为一系列块<em>patch</em>，这些块<em>patch</em>被标记化，然后作为输入馈送到编码器
Transformer。</p>
<p><img
src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FGenerative_10%2FUntitled_14.png" /></p>
<p>在ViT
VQ-GAN中，图像块被首先展平，然后被映射到一个低维潜在空间，在这个过程中，位置编码也被引入。这些序列被馈送到标准编码器
Transformer，并根据学习的码本对生成的编码进行量化。</p>
<p>这些整数代码由解码器 Transformer
模型进行处理，整体输出是一系列可以拼接在一起以形成原始图像的补丁。</p>
<p>然后，与原始 VQ-GAN 模型一样，训练的第二阶段涉及使用自回归解码器
Transformer 生成代码序列。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://raphaelhyaan.cn">Raphael Hyaan</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://raphaelhyaan.cn/2024/01/20/Generative_10/">http://raphaelhyaan.cn/2024/01/20/Generative_10/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://raphaelhyaan.cn" target="_blank">Raphael's Home</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></div><div class="post_share"></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/01/20/Generative/" title="生成式神经网络总览"><img class="cover" src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fgenerative.jpg" onerror="onerror=null;src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">生成式神经网络总览</div></div></a></div><div class="next-post pull-right"><a href="/2024/01/20/Generative_9/" title="Chapter 9 Transformers"><img class="cover" src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fgenerative.jpg" onerror="onerror=null;src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Chapter 9 Transformers</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/11/22/DCGAN-1/" title="DCGAN"><img class="cover" src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/post%2FDCGAN%2FUntitled.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-11-22</div><div class="title">DCGAN</div></div></a></div><div><a href="/2024/01/20/Generative/" title="生成式神经网络总览"><img class="cover" src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fgenerative.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-20</div><div class="title">生成式神经网络总览</div></div></a></div><div><a href="/2024/01/20/Generative_1/" title="Chapter 1 Generative Modeling"><img class="cover" src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fgenerative.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-20</div><div class="title">Chapter 1 Generative Modeling</div></div></a></div><div><a href="/2024/01/20/Generative_2/" title="Chapter 2 Deep Learning"><img class="cover" src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fgenerative.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-20</div><div class="title">Chapter 2 Deep Learning</div></div></a></div><div><a href="/2024/01/20/Generative_3/" title="Chapter 3 Variational Autoencoders 自动变分编码器"><img class="cover" src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fgenerative.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-20</div><div class="title">Chapter 3 Variational Autoencoders 自动变分编码器</div></div></a></div><div><a href="/2024/01/20/Generative_4/" title="Chapter 4 Generative Adversarial Networks 生成对抗网络"><img class="cover" src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fgenerative.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-20</div><div class="title">Chapter 4 Generative Adversarial Networks 生成对抗网络</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Fe747243b42e6168d02fdf8bccbbd4ea.jpg" onerror="this.onerror=null;this.src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffriend_404.gif'" alt="avatar"/></div><div class="author-info__name">Raphael Hyaan</div><div class="author-info__description">何日可谓归去来</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">99</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">27</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/raphaelhyaan"><i class="fab fa-github"></i><span>Bonjour</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/raphaelhyaan" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:raphael.ma.yuhan@outlook.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">仰观宇宙之大，俯察品类之盛</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#chapter-10-advanced-gans-%E5%90%84%E7%A7%8D%E5%90%84%E6%A0%B7%E7%9A%84gan"><span class="toc-number">1.</span> <span class="toc-text">Chapter 10 Advanced GANs
各种各样的GAN</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#progan"><span class="toc-number">2.</span> <span class="toc-text">ProGAN</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#progressive"><span class="toc-number">2.1.</span> <span class="toc-text">Progressive</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="toc-number">2.2.</span> <span class="toc-text">网络结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E4%BA%9B%E5%85%B6%E4%BB%96%E7%BB%86%E8%8A%82"><span class="toc-number">2.3.</span> <span class="toc-text">一些其他细节</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%8F%E6%89%B9%E6%AC%A1%E6%A0%87%E5%87%86%E5%81%8F%E5%B7%AE-minibatch-standard-deviation"><span class="toc-number">2.3.1.</span> <span class="toc-text">小批次标准偏差
Minibatch standard deviation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9D%87%E8%A1%A1%E5%AD%A6%E4%B9%A0%E7%8E%87-equalized-learning-rates"><span class="toc-number">2.3.2.</span> <span class="toc-text">均衡学习率 Equalized
learning rates</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%90%E5%83%8F%E7%B4%A0%E5%BD%92%E4%B8%80%E5%8C%96-pixelwise-normalization"><span class="toc-number">2.3.3.</span> <span class="toc-text">逐像素归一化 Pixelwise
normalization</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#stylegan"><span class="toc-number">3.</span> <span class="toc-text">StyleGAN</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E6%9E%84"><span class="toc-number">3.1.</span> <span class="toc-text">结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#mapping-network"><span class="toc-number">3.2.</span> <span class="toc-text">Mapping Network</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#synthesis-network"><span class="toc-number">3.3.</span> <span class="toc-text">Synthesis Network</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#adaln%E5%B1%82"><span class="toc-number">3.3.1.</span> <span class="toc-text">AdalN层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A3%8E%E6%A0%BC%E6%B7%B7%E5%90%88-style-mixing"><span class="toc-number">3.3.2.</span> <span class="toc-text">风格混合 Style Mixing</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E5%8F%98%E5%8C%96-stochastic-variation"><span class="toc-number">3.3.3.</span> <span class="toc-text">随机变化 Stochastic
variation</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#stylegan2"><span class="toc-number">4.</span> <span class="toc-text">StyleGAN2</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9D%83%E9%87%8D%E8%B0%83%E5%88%B6%E4%B8%8E%E8%A7%A3%E8%B0%83-weight-modulation-and-demodulation"><span class="toc-number">4.1.</span> <span class="toc-text">权重调制与解调
Weight Modulation and Demodulation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B7%AF%E5%BE%84%E9%95%BF%E5%BA%A6%E6%AD%A3%E5%88%99%E5%8C%96-path-length-regularization"><span class="toc-number">4.2.</span> <span class="toc-text">路径长度正则化
Path Length Regularization</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9D%9E%E6%B8%90%E8%BF%9B%E5%BC%8F%E7%94%9F%E9%95%BF-no-progressive-growing"><span class="toc-number">4.3.</span> <span class="toc-text">非渐进式生长 No
Progressive Growing</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#self-attention-gan-sagan"><span class="toc-number">5.</span> <span class="toc-text">Self-Attention GAN
(SAGAN)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#biggan"><span class="toc-number">6.</span> <span class="toc-text">BigGAN</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#vq-gan"><span class="toc-number">7.</span> <span class="toc-text">VQ-GAN</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#vit-vq-gan"><span class="toc-number">8.</span> <span class="toc-text">ViT VQ-GAN</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/05/12/mq/" title="量子力学总览"><img src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fmq.png" onerror="this.onerror=null;this.src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="量子力学总览"/></a><div class="content"><a class="title" href="/2024/05/12/mq/" title="量子力学总览">量子力学总览</a><time datetime="2024-05-12T09:55:11.000Z" title="发表于 2024-05-12 17:55:11">2024-05-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/05/12/mq-9/" title="量子简谐系统的波函数 Wavefunctions for the Harmonic Oscillator"><img src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fmq.png" onerror="this.onerror=null;this.src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="量子简谐系统的波函数 Wavefunctions for the Harmonic Oscillator"/></a><div class="content"><a class="title" href="/2024/05/12/mq-9/" title="量子简谐系统的波函数 Wavefunctions for the Harmonic Oscillator">量子简谐系统的波函数 Wavefunctions for the Harmonic Oscillator</a><time datetime="2024-05-12T09:55:10.000Z" title="发表于 2024-05-12 17:55:10">2024-05-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/05/12/mq-8/" title="振动系统 Vibrating Systems"><img src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fmq.png" onerror="this.onerror=null;this.src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="振动系统 Vibrating Systems"/></a><div class="content"><a class="title" href="/2024/05/12/mq-8/" title="振动系统 Vibrating Systems">振动系统 Vibrating Systems</a><time datetime="2024-05-12T09:55:09.000Z" title="发表于 2024-05-12 17:55:09">2024-05-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/05/12/mq-7/" title="量子/经典力学联系 Le lien classique-quantique"><img src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fmq.png" onerror="this.onerror=null;this.src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="量子/经典力学联系 Le lien classique-quantique"/></a><div class="content"><a class="title" href="/2024/05/12/mq-7/" title="量子/经典力学联系 Le lien classique-quantique">量子/经典力学联系 Le lien classique-quantique</a><time datetime="2024-05-12T09:55:07.000Z" title="发表于 2024-05-12 17:55:07">2024-05-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/05/12/mq-15/" title="稳态微扰理论 Théorie des perturbations stationnaires"><img src="https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ftop_image%2Fmq.png" onerror="this.onerror=null;this.src='https://raphaelhyaan-1322456377.cos.ap-beijing.myqcloud.com/source%2Ffavicon.png'" alt="稳态微扰理论 Théorie des perturbations stationnaires"/></a><div class="content"><a class="title" href="/2024/05/12/mq-15/" title="稳态微扰理论 Théorie des perturbations stationnaires">稳态微扰理论 Théorie des perturbations stationnaires</a><time datetime="2024-05-12T09:55:06.000Z" title="发表于 2024-05-12 17:55:06">2024-05-12</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By Raphael Hyaan</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>